{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MALO TANNE**\n",
    "\n",
    "**CALLARD Baptiste**\n",
    "\n",
    "**4MA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet de recherche opérationnel : problème d'ordonnancement avec une machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire de notre étude "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <dl>\n",
    "<dt>I Introduction</dt>\n",
    "<dt>II MIP</dt>\n",
    "<dd> &nbsp; &nbsp; 1. Version 1</dd>\n",
    "<dd> &nbsp; &nbsp; 2. Version 2</dd>\n",
    "<dd> &nbsp; &nbsp; 3. Comparaison des MIP</dd>\n",
    "<dd> &nbsp; &nbsp; 4. Comparaison des solvers</dd>\n",
    "<dt>III Création des classes du Branch-and-Bound</dt>\n",
    "<dd> &nbsp; &nbsp; 1. Class Node</dd>\n",
    "<dd> &nbsp; &nbsp; 2. Class EnumerationTree</dd>\n",
    "<dd> &nbsp; &nbsp; 3. Etudes et comparaisons des méthodes utilisées</dd>\n",
    "<dd> &nbsp; &nbsp; 4. Comparaison plus long chemin</dd>\n",
    "<dt>IV Vérification de nos algorithmes sur un grand nombre d'instance</dt>\n",
    "<dd> &nbsp; &nbsp; 1. Comparaison Mip et Branch and Bound</dd>\n",
    "<dd> &nbsp; &nbsp; 2. Problème detecté dans la recherche du plus long chemin</dd>\n",
    "<dt>V Etude des solutions trouvées</dt>\n",
    "<dt>VI Etude des temps de calcul</dt>\n",
    "<dt>VII Conclusion</dt>\n",
    "<dt>VIII Code en Annexe</dt>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but du projet est de mettre en place un algorithme de branch-and-bound pour la résolution d'un problème ordonnancement de tâches avec une machine. Il est possible de décrire un algorithme de branch-and-bound grâce à une programmation linéaires mixtes en nombres entiers : MIP. Une fois le MIP décrit, le solver exécutera un algorithme de branch-and-bound pour le résoudre. Il nous est donné une méthode pour construire un branch-and-bound, cette méthode repose sur l'algorithme de Schrage.\n",
    "\n",
    "\n",
    "L'enjeu de ce projet est de réaliser des versions optimisées pour le MIP et le branch-and-bound. Puis dans un seconde temps, de comparer les performances des deux méthodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package pour les calculs\n",
    "\n",
    "import numpy as np\n",
    "import math \n",
    "import copy\n",
    "\n",
    "# package pour la création de graphes\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "\n",
    "# package pour la visualisation\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# package pour la gestion de tableaux\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# pour connaitre le temps de calcul\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import *\n",
    "from time import *\n",
    "\n",
    "# work space\n",
    "\n",
    "import os\n",
    "\n",
    "# plot des images\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "# Pour le MIP\n",
    "\n",
    "from pulp import *\n",
    "from time import *\n",
    "\n",
    "# générer des instances aleatoires\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque:** \n",
    "\n",
    "La première **ANNEXE** présentent toutes les versions des packages dans notre environnement. Ainsi, s'il y a un problème au niveau de version, vous pouvez vous référer à ces versions. Sinon vous pouvez nous demander que l'on vous partage notre environnement de travail. Il y a sûrement des packages qui ne sont pas utiles, mais nous n'avons pas pensé lors de la création de notre projet à définir un nouvel environnement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamment le package **graphviz_layout** qui est très utile pour afficher un arbre. En effet, il possède une fonction qui étant donné un arbre renvoie des positions des noeuds pour avoir un affichage sans que les nœuds ne se superposent. Le package **plotly.express** et **plotly.figure_factory** sont aussi très utilisés pour avoir des visualisations interactives. Il faut avoir les bonnes versions pour que cela fonctionne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choix stockage variable du problème**\n",
    "\n",
    "Pour ce projet, nous avons au fur et à mesure de notre avancée stocké des problèmes qui nous ont posé des soucis. Nous avons gardé des problèmes qui illustrent des points que nous évoquerons plus tard dans le compte rendu.\n",
    "\n",
    "Nous avons fait un premier choix pour notre modélisation, celui d'utiliser un dictionnaire pour stocker les paramètres des problèmes. Cela permet de stocker dans une unique instance les paramètres et d'être explicite quand on utilise :\n",
    "\n",
    "instance[\"a\"] -> pour accéder à la liste des $a_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = {\n",
    "    \"a\":np.array([10,13,11,20,30,0,30]),\n",
    "    \"d\":np.array([5,6,7,4,3,6,2]),\n",
    "    \"q\":np.array([7,26,24,21,8,17,0])\n",
    "}\n",
    "\n",
    "\n",
    "instance1 = {'a': np.array([146,  36,  55, 156, 113,  45, 138,  24,  84,  68]),\n",
    " 'd': np.array([48, 48, 30, 20, 19, 50, 32, 37, 24, 24]),\n",
    " 'q': np.array([180, 174, 101, 148, 126,  46,  70,  35,  11,  82])}\n",
    "\n",
    "\n",
    "instance2 = {'a': np.array([247, 210,  27, 272,  45,  79,  80, 251,  62, 140, 155,  23, 117,\n",
    "        219, 191,  36, 285, 259,  47, 177, 204,  66, 264, 221, 260, 265,\n",
    "        123, 287,  89,  90]),\n",
    " 'd': np.array([14, 25,  2,  6, 18,  5, 22, 23, 19, 17, 26,  8, 13, 13,  5, 13, 30,\n",
    "         1,  3, 22, 16, 23, 18,  2,  8, 20, 17,  9,  9, 14]),\n",
    " 'q': np.array([188,  76,  58,  59, 158, 134, 188, 262, 201, 286,   5, 245,  28,\n",
    "          7, 172, 170,  50,  33, 175, 272, 198,  90, 239, 186,  87, 111,\n",
    "        287, 268, 225,  60])}\n",
    "\n",
    "instance3 = {'a': np.array([ 25,  42,  53, 116,  73,  25,  10,  86,  93, 111]),\n",
    " 'd': np.array([25,  8, 17, 17, 43, 13, 37, 26,  3, 32]),\n",
    " 'q': np.array([ 64, 110,  11,  51,  30,   7,  34, 116,  61,  30])}\n",
    "\n",
    "instance4 = {'a': np.array([1306,  872,  558,  386,  637, 1481,  780, 1571,  553, 1220, 1092,\n",
    "         758,  522, 1541,  519,  934,  745,  362, 1575,  405,  276,  264,\n",
    "        1112, 1055, 1100, 1059, 1322,  799,  606,  155, 1432, 1391,   34,\n",
    "         974,  468, 1344,  788, 1009,  634, 1449, 1402,   81,  957,  214,\n",
    "         190,   49,  992, 1059,  985,   99,   33, 1097,  839,  710,  234,\n",
    "        1142,  675, 1209, 1186, 1232,  637,  171,   33, 1164, 1181, 1416,\n",
    "         738,  218, 1206,  435,  202,  751, 1591, 1378,  594, 1145, 1171,\n",
    "         209, 1581,  585,  180,  367,  878,  438,  845, 1225, 1527,   37,\n",
    "        1272,  664,  488, 1194,  148,  833, 1021,  938, 1019,  525,  417,\n",
    "         963]),\n",
    " 'd': np.array([17, 47, 50, 22,  1, 35,  6, 45,  3, 44, 14, 45, 43,  4, 10,  8, 50,\n",
    "        17, 48,  9, 11, 15, 19,  2,  7,  1, 31, 21,  8, 47, 48,  4,  3, 39,\n",
    "         5, 21, 49,  2, 35, 16,  4,  1, 12, 19, 44,  8,  2, 43,  9, 18, 47,\n",
    "        15, 16, 25,  4, 38,  2, 38, 41, 38, 38, 17, 23, 42, 38, 29, 44, 18,\n",
    "        36, 28, 45, 21, 28, 42, 31, 43, 36, 38, 24, 20, 29, 23, 15, 30, 14,\n",
    "        36, 33, 40,  5, 46, 42, 36, 32, 45, 34, 47, 36, 49, 44, 40]),\n",
    " 'q': np.array([ 147,  591, 1313,  893,  334, 1229,  447,  175,  654,  869, 1301,\n",
    "        1182,  798,  654, 1008,  388,   73,  502,  665,  644, 1169, 1063,\n",
    "        1268, 1349,  316,  872,  238,  388,  728,  503,  313,  351,  436,\n",
    "         502,  225, 1348, 1458, 1454,  275, 1142, 1560,  595, 1243,  970,\n",
    "          51,  871,  856, 1191, 1334,  472,  731,  724, 1156, 1445,  961,\n",
    "         311, 1167,  186, 1183,  656, 1186,   97, 1348, 1186, 1192,  699,\n",
    "         265,  158, 1291, 1368,   75,  427, 1115, 1170, 1425, 1179,  840,\n",
    "        1112, 1309,   26,  979, 1160,  909, 1302, 1406,  596,  597,  644,\n",
    "         107,  768,  111,  865,  107, 1530, 1174,  543, 1443,  511,  721,\n",
    "         107])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons choisi de mettre des images pour nos calculs prenant plusieurs heures. Pour afficher les images, si le dossier image est dans le même environnement que celui où est lancé ce Jupyter Notebook alors ce sera bon avec l'instruction en dessous : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_image = os.getcwd()+'\\\\image'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si cela ne fonctionne pas, il faut commenter la ligne d'au dessus et mettre le chemin qui mène au dossier **image**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_image = \"chemin vers image\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En annexe** nous metterons les codes qui nous ont servi à obtenir ces résultats graphiques. Nous metterons aussi des premières versions de fonctions que nous avons par la suite optimisées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. MIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1. Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut tout d'abord formuler le problème sous la forme d'un programme linéaire et de laisser un solveur (Gurobi, CBC ... dont on pourra comparer les performances) le résoudre. Ici, on aura un \"Mixed Integer Programming\" car on définit des variables binaires ($\\in \\{0,1\\}$) et des variables entières ($\\in \\mathbb{Z}$). Voici les variables que l'on définit avec $N$ le nombre de tâches à ordonner :\n",
    "- $\\forall j \\in \\{1,...,N\\},\\;t_{j}$ qui est le temps de début de la tâche j\n",
    "- $\\forall (i,j) \\in \\{1,...,N\\}^{2}, \\; i \\ne j,\\; x_{ij}$ une variable binaire égale à 1 si la tâche $j$ est effectuée après la tâche $i$ et 0 sinon.\n",
    "- $t$, le makespan\n",
    "\n",
    "Et l'on définit également : \n",
    " - $M$ = $\\sum_{j \\in {1,...,N}}\\; a_{j} + q_{j} + d_{j}$, contrainte du \"big M\" pour linéariser les implications.\n",
    "\n",
    "À l'aide de ces variables, on écrit alors la fonction objectif ainsi que les contraintes :\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\min\\;\\;&t\\\\\n",
    "\\mbox{s.t.}\\;\\;&t_{j} \\ge a_{j} &\\forall j \\in \\{1,...,N\\}\\\\\n",
    "&t \\ge t_{j} + d_{j} + q_{j} &\\forall j \\in \\{1,...,N\\}\\\\\n",
    "&t_{j} \\ge t_{i}+d_{i}-M(1-x_{ij})&\\forall (i,j) \\in \\{1,...,N\\} ^{2},i \\ne j\\\\\n",
    "&t_{j} \\le t_{i} + d_{i} - 1 + Mx_{ij}&\\forall (i,j) \\in \\{1,...,N\\} ^{2},i \\ne j\\\\\n",
    "&x_{ij} = 1 - x_{ji}& \\forall (i,j) \\in \\{1,...,N\\}^{2},i \\ne j\\\\\n",
    "&x_{ik} \\ge x_{ij} + x_{jk} - 1 &\\forall (i,j,k) \\in \\{1,...,N\\}^{3},i \\ne j \\ne k\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "La première contrainte nous dit que le début d'une tâche $j$ se situe après sa date de \"relache\" $a_{j}$. La seconde nous dit que $t = \\max_{j \\in {1,...,N}} \\; t_{j} + a_{j} + q_{j}$. Il n'y a pas besoin de rajouter une contrainte $\\le$ car nous somme en minimisation donc t va venir \"coller\" à la valeur maximum. Ensuite, les deux  contraintes suivantes sont la linéarisation de l'équivalence $\\forall (i,j)\\in \\{1,...,N\\}^{2}, x_{ij} = 1 \\iff t_{j} \\ge t_{i} + d_{i}$. Il faut également que les $x_{ij}$ forment un ordre total (si $x_{ij}$ est égal à 1 alors cela impose $x_{ji} = 0$) et qu'elles vérifient la transitivité (c'est à dire que si $i$ passe avant $j$ et $j$ passe avant $k$, alors $i$ passe avant $k$), ce qui est assuré par les deux dernières contraintes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente donc la fonction **make_mip** qui va nous créer le problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mip(instance):\n",
    "\n",
    "    #Variables\n",
    "    nb_taches = np.shape(instance[\"a\"])[0]\n",
    "    N = list(range(1,nb_taches+1))\n",
    "\n",
    "    # Les t_j : date de début de chaque tache\n",
    "    debut_taches = LpVariable.dicts(\"debut_tache\",N,lowBound = 0,cat = LpInteger)\n",
    "\n",
    "    #Les x_ij : x_ij = 1 si j passe après i \n",
    "    x = LpVariable.matrix(\"x\",(N,N),lowBound=0,upBound=1,cat=LpInteger)\n",
    "\n",
    "    #t à minimiser\n",
    "    t= LpVariable(\"t\",lowBound = 0,cat=LpInteger)\n",
    "    \n",
    "    # big M : constante qui nous assure validité (on pourrait trouver + petit)\n",
    "    M = np.sum(instance[\"a\"]) + np.sum(instance[\"q\"])+ np.sum(instance[\"d\"])\n",
    "    \n",
    "    # Probleme\n",
    "    model = LpProblem(\"Makespan\", LpMinimize)\n",
    "\n",
    "    # Fonction objectif\n",
    "    model += t, \"Makespan\"\n",
    "\n",
    "    #Contraintes\n",
    "    for j in range(0,nb_taches):\n",
    "        #début des taches après la date de relache\n",
    "        model += debut_taches[j+1] >= instance[\"a\"][j]\n",
    "        #t est le max des t_j+d_j+q_j\n",
    "        model += t >= debut_taches[j+1] + instance[\"d\"][j] + instance[\"q\"][j]\n",
    "\n",
    "        for i in range(0,nb_taches):\n",
    "            if(i!=j):\n",
    "                    #On linéarise x_ij = 1 <=> t_j >= t_i + d_i\n",
    "                    model += debut_taches[j+1]  >= debut_taches[i+1] + instance[\"d\"][i] - M*(1-x[i][j])\n",
    "\n",
    "                    model += debut_taches[j+1] <= debut_taches[i+1] + instance[\"d\"][i] - 1 + M*x[i][j]\n",
    "\n",
    "    for i in range(0,nb_taches) :\n",
    "        for j in range(0,nb_taches) :\n",
    "            if(i!=j):\n",
    "                #ordre total \n",
    "                model += x[i][j] == 1 - x[j][i]\n",
    "                for k in range(0,nb_taches) :\n",
    "                    if(i!=k and j!=k):\n",
    "                        #transitivité\n",
    "                        model += x[i][k] >= x[i][j] + x[j][k] - 1\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La résolution et l'affichage de la séquence optimale se fait grâce à **solve_print_mip**. Cette fonction possède un argument **affichage** en fonction de si l'on veut juste résoudre le problème **affichage=False** ou si l'on veut aussi afficher **affichage=True**.\n",
    "\n",
    "Cette fonction retourne les élements intéressants pour transmettre les résultats dans un dictionnaire :\n",
    "\n",
    "- duree : temps d'execution\n",
    "- makespan : valeur meilleure solution\n",
    "- t : début des tâches\n",
    "- S : séquence des tâches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons utilisé un solveur qui est présent par défaut dans notre environnement : **GLPK_CMD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_print_mip(instance,affichage = True):\n",
    "    N = np.shape(instance['a'])[0]\n",
    "    \n",
    "    model = make_mip(instance)\n",
    "    \n",
    "    #####\n",
    "    # Resolution du Problème\n",
    "    #####\n",
    "\n",
    "    # Écris le probleme dans un fichier Lp pour vérifier les erreurs\n",
    "    model.writeLP(\"make.lp\")\n",
    "    # SOLUTION\n",
    "\n",
    "\n",
    "    # Résoud avec le solveur voulu/disponible\n",
    "    starttime=time() # Obtenir le temps avant de lancer le solveur\n",
    "    # Résoud le MIP avec GLPK_CMD\n",
    "    model.solve(GLPK_CMD())\n",
    "    duree = time()-starttime\n",
    "\n",
    "\n",
    "    varsdict = {}\n",
    "    for v in model.variables():\n",
    "        # Contient les noms des variables et leurs valeurs en clé\n",
    "        varsdict[v.name] = v.varValue\n",
    "\n",
    "    # Les temps de début de chaque tâche \n",
    "    debut_tache_sol = [varsdict[\"debut_tache_\" + str(p)] for p in range(1,N+1)]\n",
    "\n",
    "    # On trouve les index initiaux de la série ordonnée\n",
    "    index_ordonne = sorted(range(len(debut_tache_sol)), key=lambda k: debut_tache_sol[k]) \n",
    "    index_ordonne = [i+1 for i in index_ordonne]\n",
    "\n",
    "    # Affichage de la séquence de tâche ordonnée\n",
    "    s = \"\"\n",
    "    for i in range(len(index_ordonne)-1):\n",
    "        s += \"Tache \" + str(index_ordonne[i]) + \" - \"\n",
    "    s+= \"Tache \" + str(index_ordonne[len(index_ordonne)-1])\n",
    "\n",
    "    \n",
    "    if affichage :\n",
    "        \n",
    "        print(\"\\n###############################################\")\n",
    "        print(\"                Solve Makespan\")\n",
    "        print(\"###############################################\\n\")\n",
    "        \n",
    "        print(\"Status of the solution = \", LpStatus[model.status]) \n",
    "        print(\"Optimal Value = \", value(model.objective))\n",
    "        \n",
    "        print(\"Solution time =  \", np.round(duree,5),\"\\n\")\n",
    "        \n",
    "\n",
    "        print(\"Ordre de la séquence :\")\n",
    "        print(s)\n",
    "\n",
    "    \n",
    "    return {\"duree\":duree,\n",
    "           \"makespan\":value(model.objective),\n",
    "           \"t\":dict(zip([i for i in range(N)],debut_tache_sol)),\n",
    "           \"S\": index_ordonne}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois une solution trouvée, nous avons décider de la représenter visuellement sous la forme d'un diagramme de Gantt l'ordonnancement des tâches. Pour cela nous avons fait la fonction **plot_ordonnacement_taches**. Cette fonction est intéractive, ainsi en déplaçant la souris sur le digramme de Gantt on peut avoir les temps de début de tâche et fin de tâche... C'est pratique quand on a beaucoup de tâches car c'est compliqué de lire à quel moment exactement commence une tâche.\n",
    "\n",
    "Par exemple pour la dernière tâche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\diag_gantt.JPG\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code pour diagramme de **Gantt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime(x):\n",
    "    return datetime.fromtimestamp(31536000+x*24*3600).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def plot_ordonnacement_taches(debut_taches,instance,makespan):\n",
    "    nb_tache = len(debut_taches.keys())\n",
    "    df = []\n",
    "\n",
    "    cpt = 0\n",
    "    for k in range(nb_tache):\n",
    "        cpt+=1\n",
    "        title_task = \"Tache_\" + str(cpt)\n",
    "        \n",
    "        df.append(dict(Task = title_task,Start = convert_to_datetime(instance[\"a\"][k]-1),Finish = convert_to_datetime(instance[\"a\"][k]),Resource = \"Date minimum de début\"))\n",
    "        df.append(dict(Task = title_task,Start = convert_to_datetime(debut_taches[k]-1),Finish = convert_to_datetime(debut_taches[k]),Resource = \"Début Tâche\"))\n",
    "        df.append(dict(Task = title_task,Start = convert_to_datetime(debut_taches[k]),Finish = convert_to_datetime(debut_taches[k] + instance[\"d\"][k]),Resource = \"Déroulé de la tâche\"))\n",
    "        df.append(dict(Task = title_task,Start = convert_to_datetime(debut_taches[k] + instance[\"d\"][k]),Finish = convert_to_datetime(debut_taches[k] + instance[\"d\"][k] + instance[\"q\"][k]),Resource = \"Attente fin de tâche\"))\n",
    "    \n",
    "\n",
    "    colors = {\"Date minimum de début\": 'rgb(220, 0, 0)',\n",
    "          \"Début Tâche\": 'rgb(220, 0, 150)',\n",
    "          \"Déroulé de la tâche\": 'rgb(0, 255, 0)',\n",
    "          \"Attente fin de tâche\" : 'rgb(255,255,0)'\n",
    "             }\n",
    "\n",
    "    fig = ff.create_gantt(df, colors=colors, index_col='Resource', show_colorbar=True,\n",
    "                        group_tasks=True)\n",
    "\n",
    "    num_tick_labels = np.linspace(start = 0, stop = makespan, num = makespan+1, dtype = int)\n",
    "    date_ticks = [convert_to_datetime(x) for x in num_tick_labels]\n",
    "\n",
    "    fig.layout.xaxis.update({\n",
    "            'tickvals' : date_ticks,\n",
    "            'ticktext' : num_tick_labels\n",
    "        })\n",
    "    fig.update_xaxes(tickangle=60)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification sur l'instance du TP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons le temps retourné par le MIP ainsi que la séquence pour le problème de référence donné dans le sujet du TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = solve_print_mip(instance)\n",
    "plot_ordonnacement_taches(test[\"t\"],instance,test[\"makespan\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trouve bien le même temps optimale et une séquence valide. L'affichage permet de bien vulgariser la solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après cette première modélisation sous forme de MIP. Il s'avère alors que l'on a des contraintes en trop. En effet, on peut enlever les contraintes : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&t_{j} \\ge t_{i} + d_{i} \\Rightarrow x_{ij} = 1 \\\\\n",
    "&x_{ik} \\ge x_{ij} + x_{jk} - 1\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "En effet, de part la relation d'ordre total et la première implication de l'équivalence, ces contraintes étaient en trop. En particulier, la supression de la transitivité nous retire $N^{3}$ contraintes, ce qui est non négligeable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, on refait des fonctions équivalentes pour cette nouvelle définition du problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mip_2(instance):\n",
    "\n",
    "    #Variables\n",
    "    nb_taches = np.shape(instance[\"a\"])[0]\n",
    "    N = list(range(1,nb_taches+1))\n",
    "\n",
    "    # Les t_j : date de début de chaque tache\n",
    "    debut_taches = LpVariable.dicts(\"debut_tache\",N,lowBound = 0,cat = LpInteger)\n",
    "\n",
    "    #Les x_ij : x_ij = 1 si j passe après i  (il faudrait définir pour i<j pour casser la symétrie)\n",
    "    x = LpVariable.matrix(\"x\",(N,N),lowBound=0,upBound=1,cat=LpInteger)\n",
    "\n",
    "    #t à minimiser\n",
    "    t= LpVariable(\"t\",lowBound = 0,cat=LpInteger)\n",
    "    \n",
    "    # big M : constante qui nous assure validité (on pourrait trouver + petit)\n",
    "    M = np.sum(instance[\"a\"]) + np.sum(instance[\"q\"])+ np.sum(instance[\"d\"])\n",
    "    \n",
    "    # Probleme\n",
    "    model = LpProblem(\"Makespan\", LpMinimize)\n",
    "\n",
    "    # Fonction objectif\n",
    "    model += t, \"Makespan\"\n",
    "\n",
    "    #Contraintes\n",
    "    for j in range(0,nb_taches):\n",
    "        #début des taches après la date de relache\n",
    "        model += debut_taches[j+1] >= instance[\"a\"][j]\n",
    "        #t est le max des t_j+d_j+q_j\n",
    "        model += t >= debut_taches[j+1] + instance[\"d\"][j] + instance[\"q\"][j]\n",
    "\n",
    "        for i in range(0,nb_taches):\n",
    "            if(i!=j):\n",
    "                    #On linéarise x_ij = 1 <=> t_j >= t_i + d_i\n",
    "                    model += debut_taches[j+1]  >= debut_taches[i+1] + instance[\"d\"][i] - M*(1-x[i][j])\n",
    "\n",
    "    for i in range(0,nb_taches) :\n",
    "        for j in range(0,nb_taches) :\n",
    "            if(i!=j):\n",
    "                #ordre total \n",
    "                model += x[i][j] == 1 - x[j][i]\n",
    "    \n",
    "    return(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_print_mip_2(instance,affichage = True):\n",
    "    N = np.shape(instance['a'])[0]\n",
    "    \n",
    "    model = make_mip_2(instance)\n",
    "    \n",
    "    #####\n",
    "    # Resolution du Problème\n",
    "    #####\n",
    "\n",
    "    # Écris le probleme dans un fichier Lp pour vérifier les erreurs\n",
    "    model.writeLP(\"make.lp\")\n",
    "    # SOLUTION\n",
    "\n",
    "\n",
    "    # Résoud avec le solveur voulu/disponible\n",
    "    starttime=time() # Obtenir le temps avant de lancer le solveur\n",
    "    # Résoud le MIP\n",
    "    model.solve(GLPK_CMD())\n",
    "    duree = time()-starttime\n",
    "\n",
    "\n",
    "    varsdict = {}\n",
    "    for v in model.variables():\n",
    "        # Contient les noms des variables et leurs valeurs en clé\n",
    "        varsdict[v.name] = v.varValue\n",
    "\n",
    "    # Les temps de début de chaque tâche \n",
    "    debut_tache_sol = [varsdict[\"debut_tache_\" + str(p)] for p in range(1,N+1)]\n",
    "\n",
    "    # On trouve les index initiaux de la série ordonnée\n",
    "    index_ordonne = sorted(range(len(debut_tache_sol)), key=lambda k: debut_tache_sol[k]) \n",
    "    index_ordonne = [i+1 for i in index_ordonne]\n",
    "\n",
    "    # Affichage de la séquence de tâche ordonnée\n",
    "    s = \"\"\n",
    "    for i in range(len(index_ordonne)-1):\n",
    "        s += \"Tache \" + str(index_ordonne[i]) + \" - \"\n",
    "    s+= \"Tache \" + str(index_ordonne[len(index_ordonne)-1])\n",
    "\n",
    "    \n",
    "    if affichage :\n",
    "        \n",
    "        print(\"\\n###############################################\")\n",
    "        print(\"                Solve Makespan\")\n",
    "        print(\"###############################################\\n\")\n",
    "        \n",
    "        print(\"Status of the solution = \", LpStatus[model.status]) \n",
    "        print(\"Optimal Value = \", value(model.objective))\n",
    "        \n",
    "        print(\"Solution time =  \", np.round(duree,5),\"\\n\")\n",
    "        \n",
    "\n",
    "        print(\"Ordre de la séquence :\")\n",
    "        print(s)\n",
    "\n",
    "    \n",
    "    return {\"duree\":duree,\n",
    "           \"makespan\":value(model.objective),\n",
    "           \"t\":dict(zip([i for i in range(N)],debut_tache_sol)),\n",
    "           \"S\": index_ordonne}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions donc cela sur la même instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = solve_print_mip_2(instance)\n",
    "plot_ordonnacement_taches(test[\"t\"],instance,test[\"makespan\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque ainsi que l'on n'obtient pas la même séquence. Ce qui n'est pas aberrant puisque suivant la façon dont le solveur crée son arbre et le parcours, on peut ne pas couper au même endroit. On voit déjà sur cette première instance que le temps pour résoudre le problème est meilleur que celui du premier MIP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche alors à comparer ces deux modèles MIP afin de savoir lequel nous allons garder pour la comparaison avec le Branch and Bound. On génère donc des instances aléatoires qui vont servir de comparaison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_instance_test(n_jobs,d_max):\n",
    "    \n",
    "    K = int(np.random.randint(1,25,1))\n",
    "    \n",
    "    a_max = q_max = n_jobs*d_max*K/50\n",
    "    # +1 car sinon ça génère entre borne_inf et borne_sup-1\n",
    "    instance = { \"a\" : np.random.randint(1,a_max+1, size=n_jobs),\n",
    "               \"d\" : np.random.randint(1,d_max+1, size=n_jobs),\n",
    "               \"q\" : np.random.randint(1,q_max+1, size=n_jobs)}\n",
    "    \n",
    "    return(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3.Comparaison des MIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant comparer les temps de calcul des deux MIPs, pour des nombres de tâches allant de 4 à 10. Pour un nombre de tâche i$\\in$[0,10] nous génèrerons 20 problèmes. Nous avons représenté le temps moyen de résolution des deux MIPs.\n",
    "\n",
    "Ce qui nous intéresse ici ce n'est pas le temps dans l'absolu. Il nous faut comparer les temps relatifs. En effet, les solveurs que nous utilisons ne demandent pas de licence. Ils ne sont donc pas les plus performants. Il faut donc chercher à avoir le meilleur temps de calcul mais relativement à un solver que l'on se fixe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les temps de calcul sont en secondes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le code est en ANNEXE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\comp_mip1_mip_2.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectivement, lorsque l'on retire des contraintes, le modèle est plus rapidement résolu et cela pour toutes les instances dans notre cas. Nous choisirons donc ce modèle pour les futures comparaisons. En ordre de grandeur, le MIP 2 est deux fois plus rapide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi conclure de cette étude que le temps de calcul augmente exponentiellement en fonction du nombre de tâches à résoudre. Pour les solveurs que nous avons testés, des problèmes d'une dizaine de tâches peuvent être trop complexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.4.Comparaison solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons voulu regarder le meilleur solver que nous avions à disposition dans notre environnement, en comprant les temps de calcul avec le modèle choisi précédemment. Cela peut déjà permettre d'avoir un borne supérieure des performances que l'on pourrait obtenir avec des solveurs performants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme les solveurs disponible diffère selon les ordinateurs. Nous avons choisi de ne mettre que des images de nos résultats. En effet, nous avons dû faire une fonction spécifique pour tous les solveurs car ils fonctionnent tous différemment. De plus, le temps de calcul était relativement long.\n",
    "\n",
    "Nous avons comparé chacun des solveurs sur 20 instances aléatoires de 4 à 10 tâches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les solveurs qui sont disponibles dans notre environnement sont les suivants : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le code est en ANNEXE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\solver_dispo.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila les performances que l'on obtient pour les solveurs. Nous avons une fois de plus moyenné les temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\solver_res.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le solveur GUROBI est le plus constant. Mais la licence payante est nécessaire pour des problèmes de taille plus importants. Le solveur CPLEX_PY ou GLPK_CMD serait donc le plus adapté ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons déjà conclure que le nombre de contrainte que l'on impose dans notre MIP change significativement le temps de calcul. De plus, pour notre prochaine étude, il faut faire attention dans nos comparaisons entre le MIP et le branch-and-bound. En effet, nous avons pu faire tourner le MIP qu'avec des solveurs basiques. Nous avons donc une borne supérieure des performances que l'on peut atteindre. On ne peut pas affirmer qu'il n'existe pas de solveurs très performants sur ce type de problème. \n",
    "\n",
    "Pour les solveurs disponibles, nous pouvons conclure que le MIP n'est pas performant sur les grandes instances. On ne peut pas resoudre de manière systématique des problèmes avec plus de 15 tâches par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Création des classes du Branch and Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.1 Classe Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce projet, il est proposé de résoudre le problème d'ordonnancement des tâches en utilisant une deuxième méthode. Nous avons résolu le problème grâce à une méthode de Branch and Bound. Pour la règle de branchement, nous avons utilisé l'algorithme de Schrage pour avoir une borne primale à chaque noeud. Puis, il nous a été proposé une règle de branchement en déterminant un nœud critique.\n",
    "\n",
    "Pour implémenter notre problème, nous avons créé deux classes. La première classe a pour but de définir le concept de **noeud**. Nous allons présenter les différentes instances d'un nœud et la variable globale qui les définissent.\n",
    "\n",
    "**Variable globale**:\n",
    "\n",
    "   - **Number** : cette variable permet d'associer un numéro unique à chaque noeud\n",
    "\n",
    "**Instances**:\n",
    "\n",
    "   - **number** : Stocke le numéro unique de chaque noeud\n",
    "           - entier\n",
    "   - **number_proceed** : Stocke le numéro de traitement du noeud (utilisé pour la visualisation)\n",
    "           - entier\n",
    "   - **instance** : Dictionnaire avec les $a_i~d_i~q_i$\n",
    "           - dictionnaire\n",
    "   - **S** : Séquence de Schrag\n",
    "           - list\n",
    "           - None si élagué car borne inf > borne primale\n",
    "   - **t** : Temps asssocié à la séquence de Schrag\n",
    "           - dictionnaire\n",
    "           - None si élagué car borne inf > borne primale\n",
    "   - **makespan** : Valeur du plus long chemin dans le graph conjonctif\n",
    "           - entier\n",
    "           - None si élagué car borne inf > borne primale\n",
    "   - **C** : Plus long chemin dans le graphe conjonctif sans \"s\" et \"t\"\n",
    "           - list\n",
    "           - None si élagué car borne inf > borne primale\n",
    "   - **critic_task** : Tâche critique\n",
    "           - entier si existence\n",
    "           - None sinon\n",
    "   - **J** : Ensemble des tâche après la tâche critique\n",
    "           - liste si existence de la tâche critique\n",
    "           - None sinon\n",
    "   - **prune** : Si le noeud est élagué\n",
    "           - True si élagué\n",
    "           - None sinon\n",
    "   - **lower_bound** : Borne inférieure du noeud \n",
    "           - entier\n",
    "   - **father** : Père du noeud\n",
    "           - Adresse de son père\n",
    "           - None si racine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    # variable de la classe Node\n",
    "    Number = 0\n",
    "    \n",
    "    def __init__(self,instance,father):\n",
    "        Node.Number = Node.Number+1\n",
    "        \n",
    "        #######################################\n",
    "        # initialisation des instances d'un noeud\n",
    "        #######################################\n",
    "        \n",
    "        # numéro unique du noeud -> utilisé pour l'affichage\n",
    "        self.number = Node.Number\n",
    "        # numéro de traintement d'un noeud \n",
    "        self.number_proceed = None\n",
    "        # dictionnaire des instances\n",
    "        self.instance = instance\n",
    "        \n",
    "        \n",
    "        ########################################\n",
    "        # calcul d'une séquence S valide et des temps associés\n",
    "        #######################################\n",
    "        \n",
    "        \n",
    "         # séquence valide avec Schrage        \n",
    "        self.S = None\n",
    "        # temps des tâches\n",
    "        self.t = None\n",
    "        \n",
    "        \n",
    "        ###################################\n",
    "        # calcul dans le graphe conjonctif\n",
    "        ###################################\n",
    "        \n",
    "        # valeur du plus long chemin\n",
    "        self.makespan = None\n",
    "        # Plus long chemin de s à t sans s ni t\n",
    "        self.C = None\n",
    "        \n",
    "        ####################################\n",
    "        # calcul tâche critique\n",
    "        ####################################\n",
    "        \n",
    "        # tâche critique\n",
    "        self.critic_task = None\n",
    "        # ensemble des tâches après la tâche critique\n",
    "        self.J = None\n",
    "        \n",
    "        ###################################\n",
    "        # Elagage et successeurs\n",
    "        ###################################\n",
    "        \n",
    "        # si le noeuf est prune = True\n",
    "        self.prune = None\n",
    "              \n",
    "        \n",
    "        # si father is None alors c'est le noeud racine sinon tous les noeuds auront un père et donc une borne inf\n",
    "        \n",
    "        if father is None:\n",
    "            pass\n",
    "        else:\n",
    "             # calcul de la borne inf à la création d'un noeud\n",
    "                \n",
    "            L = father.lower_bound\n",
    "            h_J = min(father.instance[\"a\"][father.J])+sum(father.instance[\"d\"][father.J])+min(father.instance[\"q\"][father.J])\n",
    "            h_J_jc = min(self.instance[\"a\"][np.array([father.critic_task] + list(father.J))])+sum(self.instance[\"d\"][np.array([father.critic_task] + list(father.J))])+min(self.instance[\"q\"][np.array([father.critic_task] + list(father.J))])\n",
    "            \n",
    "            self.lower_bound = max(L,h_J,h_J_jc)\n",
    "        \n",
    "        # pour un noeud on a besoin de son pére pour le calcul de sa borne inférieure\n",
    "        self.father = father\n",
    "   \n",
    "\n",
    "    #############################################\n",
    "    #  Visualisation\n",
    "    #############################################\n",
    "    \n",
    "    # permet de visualiser les instances d'un noeud\n",
    "    \n",
    "    def describe(self): \n",
    "        \"\"\"\n",
    "        fonction pour afficher les attributs d'un noeuds\n",
    "        \"\"\"\n",
    "        print(\"a\",self.instance['a'])\n",
    "        print(\"q\",self.instance['q'])\n",
    "        print(\"d\",self.instance['d'])\n",
    "        print(\"J\",self.J)\n",
    "        print(f\"S : {self.S} \\n\"+f\"t : {self.t} \\n\"+f\" lower_bound : {self.lower_bound} \\n\"+f\" makespan : {self.makespan} \\n\"+ f\" C : {self.C} \\n\"+f\" critical task : {self.critic_task} \\n\"+f\" J : {self.J} \\n\"+f\" prune : {self.prune}\"+ \"\\n\\n\\n\\n\\n\")             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons aussi mis des fonctions en dehors de la classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **compute_S** permet de retourner la séquence de l'algorithme de Shrage ainsi que le temps d'affectation. Elle prend en paramètre le dictionnaire des instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_S(instance):\n",
    "        \n",
    "        # nombre de tâches\n",
    "        N = len(instance[\"a\"])\n",
    "        \n",
    "        # temps associé à chaque tâche \n",
    "        schedule_time = {}\n",
    "        \n",
    "        # liste chronologique des tâches effectuées\n",
    "        S = []\n",
    "        \n",
    "        # masque de booléan pour savoir les tâches déjà affectées\n",
    "        # True si la tâche n'est pas affectée (dans le complémentaire de U)\n",
    "        # False si la tâche est affectée (dans U)\n",
    "        \n",
    "        U_ = [True]*N\n",
    "        t = np.min(instance[\"a\"][U_])\n",
    "        \n",
    "        # tant qu'il y a des tache dans U_\n",
    "        while any(U_):         \n",
    "            \n",
    "            # on calcule les conditions que doit vérifier i            \n",
    "            cond_a = np.where(instance[\"a\"]<=t)[0]\n",
    "            cond_U = np.where(U_)[0]\n",
    "            cond = np.intersect1d(cond_a,cond_U)\n",
    "            \n",
    "            # on récupère la tâche i parmi les tâches valides qui maximisent q et d'argument maximum\n",
    "            i = cond[np.argmax(instance[\"q\"][cond])]\n",
    "            \n",
    "            \n",
    "            # on enlève i de U_\n",
    "            U_[i] = False\n",
    "            \n",
    "            # on stocke les valeurs\n",
    "            schedule_time[i] = t\n",
    "            S.append(i)\n",
    "            \n",
    "            # mise à jour de t\n",
    "            t = max(t+instance[\"d\"][i],np.min(instance[\"a\"][U_]))\n",
    "            \n",
    "            # si il ne reste d'une seule tâche on peut directement l'affecter\n",
    "                        \n",
    "            if(sum(U_)==1):\n",
    "                i = np.argmax(U_)\n",
    "                schedule_time[i] = t\n",
    "                U_[i] = False\n",
    "                S.append(i)\n",
    "                \n",
    "        return {\"schedule_time\":schedule_time,\"S\":S}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la recherche de la tâche critique, il faut rechercher le plus long chemin dans un graphe. Nous avons dans un premier temps fait l'algorithme de Bellman (**Le code du Bellman est présenté en ANNEXE**). Puis nous avons fait un second algorithme qui prend en compte la forme du graphe.\n",
    "\n",
    "L'algorithme de Bellman est en **n.m**. Notre algorithmes est en **m** car il parcourt seulement deux fois les noeuds situés \"au centre\" du graphe conjonctif.\n",
    "\n",
    "\n",
    "**Remarque**: Nos deux algorithmes ont été testés sur un grand nombre d'instance et fonctionnent tous les deux. Nous avons choisi de garder la seconde version car nous avons observé qu'en moyenne nous avions des meilleures performances. Nous présenterons les résultats ultérieurement.\n",
    "\n",
    "\n",
    "Nous avons expliqué à la main comment nous avons procédé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\longest_path.JPG\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le code de **makespan_2** qui retourne le plus long chemin **C** et sa **valeur**. Cette fonction prend en paramètre un graphe conjonctif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makespan_2(G):\n",
    "    \n",
    "    distances = {}\n",
    "    distances['s'] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Le noeud initial est celui qui n'a qu'un seul prédécesseur : 's'\n",
    "    for node in list(G.nodes):\n",
    "        if(len(list(G.predecessors(node))) == 1):\n",
    "            noeud_courant = node\n",
    "            \n",
    "    distances[noeud_courant] = G['s'][noeud_courant]['weight']\n",
    "    \n",
    "    predecesseurs = {}\n",
    "    predecesseurs[noeud_courant] = 's'\n",
    "        \n",
    "    # On regarde sur tout les noeuds \"tâches\"\n",
    "    cpt = 0\n",
    "    while(cpt != len(list(G.nodes))-3):\n",
    "        index = np.where(np.array(list(G.successors(noeud_courant))) != 't')[0][0]\n",
    "        successor = list(G.successors(noeud_courant))[index]\n",
    "\n",
    "        #On choisit soit le chemin passant par le prédécésseur, soit celui venant de t\n",
    "        if(G['s'][successor]['weight'] > distances[noeud_courant] + G[noeud_courant][successor]['weight']):\n",
    "            distances[successor] = G['s'][successor]['weight']\n",
    "            predecesseurs[successor] = 's'\n",
    "        else:\n",
    "            distances[successor] = distances[noeud_courant] + G[noeud_courant][successor]['weight']\n",
    "            predecesseurs[successor] = noeud_courant\n",
    "        \n",
    "        cpt+=1\n",
    "        noeud_courant = successor\n",
    "        \n",
    "    \n",
    "    # On a donc les distances pour toutes les tâches du milieu\n",
    "    # Pour le plus long chemin jusq'à s, il suffit de prendre le max entre distance_tache_milieu + distance jusqu'à s\n",
    "    lim = 0\n",
    "    for node in list(G.nodes):\n",
    "        if(node != 's' and node != 't'):\n",
    "            if(distances[node] + G[node]['t']['weight'] > lim):\n",
    "                lim = distances[node] + G[node]['t']['weight']\n",
    "                predecesseurs['t'] = node\n",
    "                distances['t'] = lim\n",
    "                \n",
    "    \n",
    "    # On récupère le chemin\n",
    "    path = []\n",
    "    i = 't'\n",
    "    while(predecesseurs[i] !='s'):\n",
    "        i = predecesseurs[i]\n",
    "        path.insert(0,i)\n",
    "            \n",
    "    return{\"makespan\":distances['t'],\"path\":np.array(path)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **critical_task** permet de retourner l'ensemble critique J ainsi que la tâche critique si elle existe. Si il n'y a pas de tâche critique alors les variables prennent la valeur None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critical_task(instance,C):\n",
    "        \n",
    "        # on regarde si la dernière tache dans C est possède le plus petit q\n",
    "        if(instance[\"q\"][C[-1]]==min(instance[\"q\"][C])):\n",
    "            return {\"critic_task\":None,\"J\":None}\n",
    "        else :\n",
    "            # ensemble des sommet dans C dont la valeurs est inférieure à q_jp\n",
    "            a = instance[\"q\"][C]<instance[\"q\"][C[-1]]\n",
    "            \n",
    "            # valeur de la tache critique de plus grand indice\n",
    "            \n",
    "            critic_task = C[np.where(a)[0][-1]]\n",
    "            \n",
    "        return {\"critic_task\":critic_task,\"J\":C[np.where(a)[0][-1]+1:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **conjunctive_graph** permet de construire le graphe conjonctif à partir de la séquence de Shrage et du dictionnaire d'instance. Elle se contente de retourner un graphe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du graph conjonctif\n",
    "\n",
    "def conjunctive_graph(instance,S):\n",
    "        length = len(S)\n",
    "        \n",
    "        #création du graphe\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        #ajout des noeuds avec leur position pour l'affichage\n",
    "        G.add_node('s',pos=(1,length/2))\n",
    "        G.add_node('t',pos=(3,length/2))\n",
    "        for i,j in enumerate(S):\n",
    "            G.add_node(j,pos=(2,100*length-200*i))\n",
    "        \n",
    "        #ajout des arcs\n",
    "        #de s aux taches et des taches à t\n",
    "        for i in range(length):\n",
    "            G.add_weighted_edges_from([('s', i,instance[\"a\"][i])])\n",
    "            G.add_weighted_edges_from([(i, 't',instance[\"d\"][i]+instance[\"q\"][i])])\n",
    "        #entre chaque tache suivant l'ordre de S\n",
    "        for i in range(length-1):\n",
    "            G.add_weighted_edges_from([(S[i],S[i+1],instance[\"d\"][S[i]])])\n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction **visu_conj** est une fonction d'affichage du plus graphe conjonctif ainsi que du plus long chemin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visu_conj(node):\n",
    "        \n",
    "        # nombre de tâches\n",
    "        N = len(node.S)\n",
    "        \n",
    "        # graph  afficher\n",
    "        K = conjunctive_graph(node.instance,node.S)\n",
    "        \n",
    "        # paramètre graphique \n",
    "        \n",
    "        plt.figure(node.number,figsize=(24,24))\n",
    "        plt.title(f\"Graphe conjonctif de la séquence optimal S : {node.S}\")\n",
    "        pos=nx.get_node_attributes(K,'pos')\n",
    "        options = {\"edgecolors\": \"tab:gray\", \"node_size\": 800, \"alpha\": 0.9}\n",
    "        \n",
    "        # affichage du graph\n",
    "        nx.draw(K, pos=pos,with_labels=True,node_color=\"tab:red\", **options)\n",
    "        \n",
    "        # affichage du plus long chemin \n",
    "        \n",
    "        nx.draw_networkx_edges(\n",
    "            K,\n",
    "            pos,\n",
    "            edgelist=[(i,j) for i,j in zip(['s']+list(node.C),list(node.C)+['t'])],\n",
    "            width=8,\n",
    "            alpha=0.5,\n",
    "            edge_color=\"tab:green\",\n",
    "        )\n",
    "\n",
    "        # affichage des poids des arcs\n",
    "        edge_labels = nx.get_edge_attributes(K, 'weight')\n",
    "        nx.draw_networkx_edge_labels(K, pos=pos, edge_labels=edge_labels)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2 Classe EnumerationTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer une classe **EnumarationTree** qui permettera de créer des instances pour chaque problème. Une instance comportera les noeuds créer dans l'arbre ainsi que des méthodes de branchements que nous détaillerons dans la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre régle de branchement est basée sur la recherche de la tâche critique grâce à la procedure de Schrage puis à la recherche du long chemin dans le graphe conjonctif que l'on note C. Si l'on a une tâche critique alors $q_{jc}$ n'est pas de valeur minimale parmis les tâches dans C. Ainsi, on note par J l'ensemble des tâches dans le plus long chemin qui succède la tâche critique. On mettera à jour le $q_{jc}$ et $a_{jc}$ de manière à ce que la tâche critique soit traitée avant toutes les tâches dans J (mise à jour de $q_{jc}$) ou après toutes les tâches de J (mise à jour de $a_{jc}$). Ainsi, nous aurons deux nouvelles tâches filles pour le noeud en court de traitement.\n",
    "\n",
    "Nous avons donc fait deux fonctions permettant d'ajouter chacun des deux noeuds. Nous ne les avons pas mis dans la classe car ces méthodes fonctionnent de la même manière pour un noeud donnée. Elles n'ont pas de sens pour une instance EnumerationTree. Nous veillerons à l'appeler sur des noeuds qui possèdent une tâche critique dans la fonction principale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input : \n",
    "        node : une noeud avec une tâche critique\n",
    "out : \n",
    "        res : une liste comprenant la nouvelle tâche mise à jour\n",
    "        \n",
    "On retourner une liste avec un élément pour manipuler l'instance du noeud sans avoir\n",
    "a directement le nommer. C'est un moyen simple d'eviter la modification involontaire \n",
    "d'instance par adresse. On peut aussi redéfinir une fonction ___copy___ pour la classe Noeud.\n",
    "Mais cette méthode est équivalente et peu coûteuse.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def add_node_q(node):\n",
    "    \n",
    "    # on commence par créer le nouveau dictionnaire des instances\n",
    "    res = []\n",
    "    new_q = sum(node.instance[\"d\"][node.J])+node.instance[\"q\"][node.C[-1]]\n",
    "    new_instance_q = copy.deepcopy(node.instance)\n",
    "    new_instance_q[\"q\"][node.critic_task]= new_q\n",
    "    \n",
    "    # on retourne la valeur dans une liste\n",
    "    # cela permet de pouvoir travailler sur le noeud sans lui donner de nom (en quelque sort un pointeur)\n",
    "    # il faut faire attention comme ce sont des objets avec des adresses mémoires \n",
    "    # on aurait pu créer une fonction ___copy___ qui créer un objet identique mais ne pointant pas sur la meme adresse\n",
    "    \n",
    "    res.append(Node(new_instance_q,node))\n",
    "    return res\n",
    "\n",
    "\n",
    "def add_node_a(node):\n",
    "    # on commence par créer le nouveau dictionnaire des instances\n",
    "    res = []\n",
    "    new_a = sum(node.instance[\"d\"][node.J]) + min(node.instance[\"a\"][node.J])\n",
    "    new_instance_a = copy.deepcopy(node.instance)\n",
    "    new_instance_a[\"a\"][node.critic_task]= new_a\n",
    "    \n",
    "    res.append(Node(new_instance_a,node))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe **EnumationTree** possède plusieurs attributs et une variable globale que l'on va expliciter :\n",
    "\n",
    "Variable Globale :\n",
    "\n",
    "- **Nb_nodes** : permet de connaitre en quel position un noeud à été traité\n",
    "\n",
    "Instance :\n",
    "\n",
    "- **value_primal_tree** : permet d'avoir la valeur de la meilleure solution réalisable trouvé jusqu'à présent dans le parcours\n",
    "- **proceed_node** : ensemble des noeuds \n",
    "- **dict_node** : permet de stocker l'ensemble des noeuds déjà traité\n",
    "- **G** : graphe pour l'affichage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explication de notre méthode pour le branchement :\n",
    "   \n",
    "   - **Initialisation :** On commence par initialiser notre problème avec le premier noeud. \n",
    "   \n",
    "   - **Tant que :** il reste un noeud dans la liste des noeuds à traiter :\n",
    "        - **si** : la borne inférieure de ce noeud est supérieure ou égale à la meilleure solution réalisable trouvée :\n",
    "            - on élague le noeud\n",
    "        - **sinon** :\n",
    "            - on cherche la tâche critique, le makespan ...\n",
    "            - on met éventuellement à jour la borne primale de l'arbre si le makespan est meilleure\n",
    "            \n",
    "            - **si** : pas de tâche critique :\n",
    "                - on élague\n",
    "        - **si** : le noeud n'est pas élagué\n",
    "            - on créer deux successeurs qu'on ajoute à la liste des noeuds à traiter ( en fonction de comment on ajoute alors on aura différents parcours)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prendra toujours le premier noeud de la liste\n",
    "    \n",
    "- **en profondeur** : on ajoute à la fin de liste\n",
    "- **en largeur** : on ajoute au début de la liste\n",
    "- **meilleure borne inférieure** : on ajoute le noeud à l'emplacement de la liste de manière à avoir les noeuds triés par ordre décroissant de borne inférieure. Ici on maintient le tri, c'est moins couteux que rechercher le minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnumerationTree:\n",
    "    \n",
    "    # nombre de noeud pour un EnumerationTree\n",
    "    \n",
    "    Nb_nodes = 0\n",
    "    \n",
    "    def __init__(self,instance):\n",
    "        \n",
    "        ###################\n",
    "        # Instanciation\n",
    "        ###################\n",
    "        \n",
    "        # création du noeud racine\n",
    "        P0 = Node(instance,None)\n",
    "        \n",
    "        # borne dual à -math.inf\n",
    "        P0.lower_bound = -math.inf\n",
    "        \n",
    "        # valeur de la borne primale de l'arbre\n",
    "        self.value_primal_tree = math.inf\n",
    "        \n",
    "        # liste des noeuds à traiter\n",
    "        self.proceed_node = [P0]\n",
    "        \n",
    "        # stockage des noeuds \n",
    "        self.dict_node={}\n",
    "        self.dict_node[P0.number]=P0\n",
    "        \n",
    "        ###################\n",
    "        # création du graphe \n",
    "        ###################\n",
    "        \n",
    "        # nous construirons le graphe au fur et à mesure de l'ajout de noeud\n",
    "        self.G = nx.DiGraph()\n",
    "        self.G.add_node(P0.number)\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "    # cette fonction permet de choisir entre les différents parcours dans l'arbre\n",
    "\n",
    "    def add_best_lower_index(self,noeud):\n",
    "        i = 0\n",
    "        for node in self.proceed_node:\n",
    "            # la liste est triée par ordre décroissant \n",
    "            if(noeud.lower_bound<node.lower_bound):\n",
    "                return i\n",
    "            i=i+1\n",
    "        return i\n",
    "    \n",
    "\n",
    "    \n",
    "    # methode de branchement\n",
    "    def add_node_branching(self,type_parcours,node,res):\n",
    "        if type_parcours == \"largeur\" :\n",
    "            self.proceed_node.append(res[0])\n",
    "        elif type_parcours ==\"profondeur\" :\n",
    "            self.proceed_node.insert(0,res[0])\n",
    "        elif type_parcours ==\"best_lower\":\n",
    "            index = self.add_best_lower_index(res[0])\n",
    "            self.proceed_node.insert(index,res[0])\n",
    "        else :\n",
    "            print(\"error\")\n",
    "\n",
    "        # on ajoute le noeud à l'arbre    \n",
    "        self.G.add_node(res[0].number)\n",
    "        # on ajoute les arcs\n",
    "        self.G.add_edge(node.number, res[0].number)\n",
    "        self.dict_node[res[0].number]=res[0]\n",
    "    \n",
    "    \n",
    "    def creating_branching(self,type_parcours):\n",
    "        \n",
    "        # on selectionne le noeud à étudier\n",
    "        node = self.proceed_node.pop(0)\n",
    "        node.number_proceed = EnumerationTree.Nb_nodes \n",
    "        EnumerationTree.Nb_nodes +=1\n",
    "        # on regarde si on doit le traiter\n",
    "        if node.lower_bound>=self.value_primal_tree:\n",
    "            node.prune = True\n",
    "        else:\n",
    "\n",
    "            ########################################\n",
    "            # calcul d'une séquence S valide et des temps associés\n",
    "            #######################################\n",
    "            compute_S_t = compute_S(node.instance)\n",
    "            node.S = compute_S_t[\"S\"]\n",
    "            node.t = compute_S_t[\"schedule_time\"]\n",
    "\n",
    "           \n",
    "\n",
    "            ###################################\n",
    "            # calcul dans le graphe conjonctif\n",
    "            ###################################\n",
    "\n",
    "            # creation du graph\n",
    "\n",
    "            G_conj = conjunctive_graph(node.instance,node.S)\n",
    "            \n",
    "            # deuxième version du plus long chemin\n",
    "            \n",
    "            compute_makespan = makespan_2(G_conj)\n",
    "            node.makespan=compute_makespan[\"makespan\"]\n",
    "            node.C = compute_makespan[\"path\"]\n",
    "\n",
    "            # on met à jour la borne primal de l'arbre si on a une solution réalisable de meilleur coût\n",
    "            if self.value_primal_tree > node.makespan:\n",
    "                self.value_primal_tree=node.makespan\n",
    "                #print(f\"mise à jour de la borne primale {node.makespan}\")\n",
    "\n",
    "            ####################################\n",
    "            # calcul tâche critique\n",
    "            ####################################\n",
    "            compute_critic = critical_task(node.instance,node.C)\n",
    "            node.critic_task = compute_critic[\"critic_task\"]\n",
    "            node.J = compute_critic[\"J\"]\n",
    "\n",
    "            # Si il n'y a pas de tâche critique alors on a une solution locale et donc pas de besoin de lui créer des successeurs\n",
    "            if node.critic_task is None :\n",
    "                node.prune = True\n",
    "\n",
    "            \n",
    "\n",
    "            # on ajoute deux noeuds si le noeud n'est pas prune\n",
    "            if node.prune is None:\n",
    "\n",
    "                #####################################################################\n",
    "                ### Pour q ###\n",
    "                #####################################################################\n",
    "\n",
    "                res = add_node_q(node).copy()\n",
    "                # ajout du noeud en fonction du type de parcours\n",
    "                self.add_node_branching(type_parcours,node,res)\n",
    "\n",
    "                #####################################################################\n",
    "                ### Pour a ###\n",
    "                #####################################################################\n",
    "                res = add_node_a(node).copy()\n",
    "                self.add_node_branching(type_parcours,node,res)\n",
    "                \n",
    "    # cette fonction utilise la library plotly qui permet de tracer des objets de networkx\n",
    "              \n",
    "    def visu_problem(self,solution,type_parcours):\n",
    "        \n",
    "        pos = graphviz_layout(self.G, prog=\"dot\")\n",
    "        edge_x = []\n",
    "        edge_y = []\n",
    "        for edge in self.G.edges():\n",
    "            \n",
    "            x0, y0 = pos[edge[0]]\n",
    "            x1, y1 = pos[edge[1]]\n",
    "            edge_x.append(x0)\n",
    "            edge_x.append(x1)\n",
    "            edge_x.append(None)\n",
    "            edge_y.append(y0)\n",
    "            edge_y.append(y1)\n",
    "            edge_y.append(None)\n",
    "\n",
    "        edge_trace = go.Scatter(\n",
    "            x=edge_x, y=edge_y,text=\"a\",\n",
    "            line=dict(width=0.5, color='#888'),\n",
    "            hoverinfo='text',\n",
    "            mode='lines')\n",
    "\n",
    "        node_x = []\n",
    "        node_y = []\n",
    "        \n",
    "        for node in self.G.nodes():\n",
    "            x = pos[node][0]\n",
    "            y = pos[node][1]\n",
    "            node_x.append(x)\n",
    "            node_y.append(y)\n",
    "\n",
    "        node_trace = go.Scatter(\n",
    "            x=node_x, y=node_y,\n",
    "            mode='markers',\n",
    "            hoverinfo='text',\n",
    "            marker=dict(\n",
    "                color=[],\n",
    "                size=10,\n",
    "                line_width=2))\n",
    "\n",
    "        attri = []\n",
    "        color = []\n",
    "        lag = list(self.G.nodes())[0]\n",
    "        for node_index in self.G.nodes():\n",
    "            \n",
    "            # on affiche moins de chose si il y a plus de 20 tâches pour éviter les surcharges\n",
    "            if len(self.G.nodes()) < 20:\n",
    "                attri.append(f\" Ordre de traitement : {self.dict_node[node_index].number_proceed-self.dict_node[lag].number_proceed} <br> S : {np.array(self.dict_node[node_index].S)} <br> a : {np.array(self.dict_node[node_index].instance['a'])} <br> d : {np.array(self.dict_node[node_index].instance['d'])} <br> q : {np.array(self.dict_node[node_index].instance['q'])} <br> L : {self.dict_node[node_index].lower_bound} <br> Makespan : {self.dict_node[node_index].makespan} <br> Critical : {self.dict_node[node_index].critic_task} <br> J {self.dict_node[node_index].J} <br> C {self.dict_node[node_index].C} <br> Prune {self.dict_node[node_index].prune}\" )\n",
    "            else : \n",
    "                attri.append(f\" Ordre de traitement : {self.dict_node[node_index].number_proceed-self.dict_node[lag].number_proceed} <br> L : {self.dict_node[node_index].lower_bound} <br> Makespan : {self.dict_node[node_index].makespan} <br> Critical : {self.dict_node[node_index].critic_task} <br> Prune {self.dict_node[node_index].prune}\" )\n",
    "            \n",
    "            # on met les noeuds solution en jaune et les autres en bleu\n",
    "            if node_index in solution :\n",
    "                color.append(1)\n",
    "            else:\n",
    "                color.append(0)\n",
    "        \n",
    "        node_trace.marker.color = color\n",
    "       \n",
    "        node_trace.text = attri\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                     layout=go.Layout(\n",
    "                        title=f'Network graph of EnumerationTree avec un parcours en {type_parcours}',\n",
    "                        titlefont_size=16,\n",
    "                        showlegend=False,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(b=20,l=5,r=5,t=40),\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                        )\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.3 Etudes et comparaisons des méthodes utilisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tester notre Branch and Bound, nous avons mis en place une procédure de test.\n",
    "Pour cela, nous avons commencé par valider le Branch and Bound sur l'exemple illustratif du TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour résoudre le Branche & Bound et trouver la solution parmi tous les noeuds, nous avons créé une fonction **show_solution_tree** qui à partir d'une instance résout le problème puis trace l'arbre en mettant en évidence les instances de valeurs optimales. Cette méthode utilise la méthode **find_solution** qui permet de trouver les solutions où l'optimal est atteint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **show_solution_tree** permet de montrer la résolution du B&B grâce à trois parcours différents :\n",
    "\n",
    "- **parcours en largeur**\n",
    "- **parcours en profondeur**\n",
    "- **parcours en traitant le noeud qui possède une borne inférieure maximale parmi les noeuds à traiter**\n",
    "\n",
    "Cette fonction permet de comparer visuellement le nombre de noeuds créé ainsi que les solutions trouvées par les algorithmes. On ne s'occupe pas de l'unicité de la solution avec le B&B. Il peut y avoir plusieurs solutions mais nous ne chercherons seulement à en trouver une le plus rapidement possible. Cependant, nous pouvons en trouvé plusieurs mais ce n'est pas quelque chose de recherché. La fonction **show_solution_tree** retourne l'ensemble des noeuds solutions.\n",
    "\n",
    "De plus, pour la séquence optimale, nous pouvons afficher le **graphe conjonctif** pour tous les parcours. Pour ne pas allourdir l'affichage systématiquement, nous avons mis un paramètre dans la fonction **with_conj** qui permet de choisir si on affiche le graphe conjonctif. De plus, les solutions optimales seront représentées en jaune. Enfin, en-tête on retrouve des informations interessantes comme notamment le **nombre de noeud créé**.\n",
    "\n",
    "Nous voulions aussi visualiser pour chaque noeud ses paramètres comme :\n",
    "\n",
    "- sa borne inférieure\n",
    "- son makespan\n",
    "- la séquence J\n",
    "- son disctionnaire des instances\n",
    "- ...\n",
    "\n",
    "Il se trouve que lorsque le nombre de noeuds augmentent, si l'on affiche toutes ces informations alors l'arbre devient illisible.\n",
    "\n",
    "Pour cela nous avons fait une fonction d'affichage dynamique avec **plotly**. Ainsi, pour visualiser les instances d'un noeud, il faut passer la souris sur le noeud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_solution_tree(inst,with_conj=False):\n",
    "    ensem_sol_node = []\n",
    "    temp = []\n",
    "    \n",
    "    # on va resoudre pour les différents parcours\n",
    "    \n",
    "    for type_p in [\"largeur\",\"profondeur\",\"best_lower\"]:\n",
    "        # création et résolution du probleme\n",
    "        \n",
    "        E = EnumerationTree(inst)\n",
    "        while len(E.proceed_node)!=0:\n",
    "            E.creating_branching(type_p)\n",
    "\n",
    "        print(\"#### Resolution #### \\n\")\n",
    "        sol = find_solution(E)\n",
    "        for i in range(len(sol)):\n",
    "            lag = E.dict_node[list(E.G.nodes())[0]]\n",
    "            length = len(E.dict_node)\n",
    "            print(f\" #### Solution n {E.dict_node[sol[i]].number_proceed-lag.number_proceed} ####\")\n",
    "            H = conjunctive_graph(inst,E.dict_node[sol[i]].S)\n",
    "            \n",
    "            print(f\"La valeur de la solution est : {makespan_2(H)['makespan']}\")\n",
    "            print(f\"La sequence optiamle est {E.dict_node[sol[i]].S} et il y a {length} noeuds \\n\")\n",
    "            \n",
    "            # on ajoute que les noeuds qui ont des séquences que l'on a pas déjà trouvées\n",
    "            \n",
    "            if (E.dict_node[sol[i]].S not in temp):\n",
    "                ensem_sol_node.append(E.dict_node[sol[i]])\n",
    "                temp.append(E.dict_node[sol[i]].S)\n",
    "        \n",
    "        # affiche de l'arbre\n",
    "        \n",
    "        E.visu_problem(sol,type_p)\n",
    "        if with_conj:\n",
    "            visu_conj(E.dict_node[sol[i]])\n",
    "    return ensem_sol_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **find_solution** permet de trouver les indices des noeuds qui possèdent une séquence de valeure optimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_solution(E):\n",
    "    return_ind = []\n",
    "    solution = np.inf\n",
    "    for node_index in E.G.nodes():\n",
    "        \n",
    "        # les noeuds prune sans makespan on une borne inférieure supérieure à une valeur réalisable\n",
    "        # il ne sont pas à étudier\n",
    "        if(E.dict_node[node_index].makespan is not None):\n",
    "            \n",
    "            # on recherche les noeuds avec les meilleurs makespans\n",
    "            \n",
    "            # si makespan équivalent, on peut avoir plusieurs solutions\n",
    "            if(solution==E.dict_node[node_index].makespan):\n",
    "                solution = E.dict_node[node_index].makespan\n",
    "                return_ind.append(node_index)\n",
    "                \n",
    "            # si meilleur makespan\n",
    "            elif(solution>E.dict_node[node_index].makespan):\n",
    "                return_ind = []\n",
    "                solution = E.dict_node[node_index].makespan\n",
    "                return_ind.append(node_index)\n",
    "                \n",
    "    return return_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici, l'instance proposé dans le sujet ainsi que des informations sur les noeuds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\instance TP.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(instance).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**/  !  \\ pour visualiser les paramètres des noeuds, il faut passer la souris dessus**\n",
    "\n",
    "Nous avons illustrer à quoi ressemble l'affichage quand l'on passe la souris sur un noeud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\affiche_dynamique.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fonction de la taille d'un noeud, nous affichons plus ou moins de paramètres notamment les $a_i,~d_i,~q_i$.\n",
    "\n",
    "L'**ordre de traitement** est donné première ligne, c'est une donnée intéressante pour observer le parcours dans l'arbre. Les autres paramètres prennent les notations du projet et sont donc explicites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce premier exemple, nous avons utilisé l'affichage avec les graphes conjonctifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sols = show_solution_tree(instance,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour toutes les types de parcours et pour tous les noeuds, nous obtenons les mêmes valeurs ce qui est cohérent. Nous optenons egalement la même séquence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\Noeud_non_traite.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque** : Contrairement à l'exemple du cours, nous ne calculons pas Schrage et les tâches critques pour les noeuds en jaune. En effet, leur borne inférieure n'est pas strictement inférieure à la borne primal lorsqu'ils sont traités. Ainsi, on ne pourra pas trouver de meilleur chemin en itérant sous ces noeuds. C'est pourquoi dans l'affichage les noeuds au niveau des feuilles n'ont pas leur séquence de Schrage, tâche critique, makespan ... de calculé. Nous avons choisi de les représenter dans notre affichage, mais le fait d'avoir des None pour leurs paramètres n'est pas une erreur mais bien le comportement souhaité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici à quoi ressemblerait le diagramme de Gantt : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sol in sols:\n",
    "    t = sol.t\n",
    "    m = sol.makespan\n",
    "    plot_ordonnacement_taches(t,instance,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, nous avons une façon simple de visualiser la solution du problème. En entreprise, il est souvent intéressant d'avoir à la fois les compétences techniques mais aussi de savoir vulgariser et transmettre les résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.4 Comparaison des temps de calcul avec les deux algorithmes de plus long chemin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois notre Branche and Bound vérifié avec les deux plus long chemin. Nous avons choisi de déterminer quel plus long chemin garder. Comme évoqués précédemment, nous avons fait deux algorithmes de plus long chemin : Bellman et un autre avec la forme du graphe. Nous avons comparé sur 20000 problèmes avec 15 tâches aléatoires les temps moyens de calcul respectif des différents parcours. Nous avons comparé les deux versions avec les mêmes problèmes.\n",
    "\n",
    "**Remarque :** nous expliquerons dans la prochaine séquence notre méthodologie de vérification de notre Branch and Bound et de notre MIP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le code est en ANNEXE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour Bellman**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les temps sont en secondes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\Comp_makespan_1.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour la deuxième version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\Comp_makespan_2.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que nous divisons par deux les temps de calcul moyens. Ainsi, cela justifie notre nouveau plus long chemin que nous utiliserons par la suite. Nous pouvons aussi noter que sur des problèmes de taille 15 que c'est le parcours en profondeur qui est le plus efficace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Vérification sur de nos algorithmes sur des millions de problèmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons montré sur un problème que cela fonctionnait, nous allons vérifier sur un nombre plus important de problèmes générés aléatoirement que cela fonctionne également. Nous étions quasiment sur que notre MIP fonctionnait bien. Nous avons pour cela comparé le MIP au trois versions au B&B. Nous avons choisi un nombre de tâches aléatoires entre 3 et 8. Nous avons également fixé des valeurs de $d_{max}$ entre 30 et 300.\n",
    "\n",
    "Nous avons écris la fonction **gene_instance_test** qui permet de générer des instances aléatoires.\n",
    "\n",
    "En plus de vérifier si il n'y avait pas d'erreur, nous avons en parallèle relevé le temps de calcul des différentes approches. En effet, le nombre de noeuds en fonction du type de parcours est variables, et donc le temps de calcul. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons fait des tests sur des millions d'instances. Pour cela nous avons lancé un programme qui génère des instances puis vérfie que toutes les méthodes retournent la même valeur. Le temps de calul est de plus de 10 heures et donc nous allons mettre des captures d'écran des résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Le code est en ANNEXE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.1 Comparaison MIP et Branch and Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'avons pas affiché plus d'instance car l'ordinateur ne pouvait pas les afficher car cela faisait un nombre de données trop importants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les temps de calcul sont en secondes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\comp_MIP_bb_1.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons déjà voir que le MIP prend beaucoup plus de temps. Pour observer cela plus précisément, nous avons représenté la densité de présence des temps de calcul avec des **boxplot**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\comp_MIP_bb_2.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que le Mip est plus long en moyenne mais aussi que la répartition des temps de calcul est plus variable. Nous pouvons voir que les B&B ne sont pas du même ordre de grandeur que le MIP en temps de calcul. C'est pourquoi nous avons décidé de les afficher sur le même graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\comp_MIP_bb_3.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que sur des petits problèmes le parcours en profondeur est moins performants car plus variable. Le but de cette partie était de comparer le MIP avec les B&B et surtout de vérifier que les solutions coincidaient. Ainsi, nous ferons une comparaison plus approfondie par la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.2 Problème détecté dans la recherche du plus long chemin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le test des erreurs sur un nombre important d'instances a permis de mettre en lumière un choix important pour la convergence du branche and bound vers la solution optimale. Notre algorithme fonctionnait sur des 99 % des instances. Mais nous avions des erreurs et nous ne comprenions pas pourquoi.\n",
    "\n",
    "En faisant, l'algorithme à la main et tel que présenté dans le TP nous ne convergions pas vers la solution optimale mais vers la même solution que notre Branche and Bound. Finalement, le problème venait que pour certain problème, il se peut qu'il y ai plusieurs plus long chemin dans le graphe conjonctif. Si le plus long chemin sélectionné n'était pas le bon alors nous ne convergions pas vers la solution optimale. Une fois que nous avons pris cela en compte tous nos problème se sont résolus.\n",
    "\n",
    "Il fallait prendre le plus long chemin qui possédait le plus de tâche.\n",
    "\n",
    "Nous allons illustrer cela sur un exemple avec 3 tâches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = {'a': np.array([14, 37,  7]),\n",
    "  'd': np.array([84, 13, 30]),\n",
    "  'q': np.array([86, 89, 21])}\n",
    "\n",
    "pd.DataFrame(err).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on applique la procédure de Scharge alors :\n",
    "    \n",
    "- t = min(14,37,7) = 7\n",
    "\n",
    "it 1 :\n",
    "\n",
    "- on prend la tâche 2 en première car c'est la seule avec a$\\leq$7\n",
    "- t = max(7+30,14) = 37\n",
    "\n",
    "it 2 :\n",
    "    \n",
    "- on prend 1 car c'est l'argmax qui vérifie la condition\n",
    "\n",
    "Donc on en déduit que la séquence est S = (2,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_graph(S,K):\n",
    "    plt.figure(1,figsize=(12,12))\n",
    "    plt.title(f\"Graphe conjonctif de la séquence optimal S : {S}\")\n",
    "    pos=nx.get_node_attributes(K,'pos')\n",
    "    options = {\"edgecolors\": \"tab:gray\", \"node_size\": 800, \"alpha\": 0.9}\n",
    "\n",
    "    # affichage du graph\n",
    "    nx.draw(K, pos=pos,with_labels=True,node_color=\"tab:red\", **options)\n",
    "\n",
    "    # affichage du plus long chemin \n",
    "    \n",
    "\n",
    "    # affichage des poids des arcs\n",
    "    edge_labels = nx.get_edge_attributes(K, 'weight')\n",
    "    nx.draw_networkx_edge_labels(K, pos=pos, edge_labels=edge_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [2,1,0]\n",
    "K = conjunctive_graph(err,S)\n",
    "        \n",
    "# paramètre graphique \n",
    "\n",
    "view_graph(S,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, on a deux plus long chemins : **s 2 1 0 t** et **s 1 0 t** de coût : **220**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recherchons une tâche critique avec les deux plus long chemin :\n",
    "    \n",
    "   - **s 2 1 0 t** : est ce que $q_{0}$ = min (86 89 21) ? non donc 2 tâche critique\n",
    "   - **s 1 0 t** : est ce que $q_{0}$ = min (86\t89) ? oui il n'y a pas de tâche critique \n",
    "Ainsi, nous voyons que dans un cas nous avons une tâche critique et pas dans l'autre cas\n",
    "\n",
    "Nous mettons à jour $q_2~et ~ a_2$, regardons le cas de la mise à jour de $a_2$\n",
    "\n",
    "ainsi maintenant on a :\n",
    "\n",
    "$a_2$= 14 + 84 + 13 = 111\n",
    "    \n",
    "- a = 14 37 111\n",
    "- d = 84 13 30\n",
    "- q = 86 89 21\n",
    "    \n",
    "on recommence shrage : \n",
    "    on obtient 0 1 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_with_maj = {'a': np.array([14, 37,  111]),\n",
    "  'd': np.array([84, 13, 30]),\n",
    "  'q': np.array([86, 89, 21])}\n",
    "S = [0,1,2]\n",
    "K = conjunctive_graph(err_with_maj,S)\n",
    "        \n",
    "view_graph(S,K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le plus long chemin est **s 0 1 t** de valeur **200** qui est meilleur que **220**. La méthode où l'on avait mal choisi le plus long chemin ne trouvait pas de noeud critique au premier noeud et donc retournait 220. Le résultat retourné n'était pas optimal car on a trouvé une solution réalisable meilleure. D'où la nécessité de bien choisir le plus long chemin : celui qui possède le plus de tâches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons vu que rectifier ceci permettait de resoudre tous les problèmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sols = show_solution_tree(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous trouvons bien une solution avec une valeur de 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Etude des solutions trouvées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons pu voir dans nos exemples que l'on pouvait trouver en fonction du parcours (largeur, profondeur, best lower bound) des solutions différentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour illustrer ce point, nous avons relevé deux problèmes pour lesquels les parcours n'aboutissent pas à la même séquence pour une valeur optimale identique. Nous avons aussi tracé les graphes conjonctifs ainsi que les plus long chemins pour les différents parcours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cas 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur ce premier exemple, nous avons un des rares cas où nous avons trouvé que le parcours en profondeur était moins efficace que les autres parcours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sols = show_solution_tree(instance1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous étudions 87 noeuds pour le parcours en profondeur contre 83 pour les autres. Meme si nous ne parcourons pas le même nombre de noeuds, nous trouvons la même solution. Elle est présente 3 fois dans l'arbre mais elle est unique. C'est à dire la même séquence et la même valeur optimale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sol in sols:\n",
    "    t = sol.t\n",
    "    m = sol.makespan\n",
    "    plot_ordonnacement_taches(t,instance1,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cas 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous trouvons des solution avec des séquences différentes en fonction du parcours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sols = show_solution_tree(instance2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que le parcours en profondeur trouve une séquence différente des deux autres parcours. De plus, le nombre de noeuds traités est de 19 pour le parcours en profondeur contre 27 pour les autres parcours.\n",
    "\n",
    "Nous pouvons regarder les diagrammes de Gantt associés aux solutions trouvées :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sol in sols:\n",
    "    t = sol.t\n",
    "    m = sol.makespan\n",
    "    plot_ordonnacement_taches(t,instance2,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier diagramme de Gantt représente la solution trouvée avec les parcours en largeur et best lower bound tandis que le deuxième pour le parcours en profondeur. Cette visualisation est intéressante. Nous ne pouvons pas sans connaitre le domaine et sans l'expertise métier donner une meilleure séquence. Nous pouvons juste dire que le parcours en profondeur est meilleur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cas 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous trouvons 3 solutions différentes (séquences différentes) dans chacun des parcours en un nombre d'itération faible : 9 noeuds et 7 noeuds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sols = show_solution_tree(instance3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sol in sols:\n",
    "    t = sol.t\n",
    "    m = sol.makespan\n",
    "    plot_ordonnacement_taches(t,instance3,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons bien avec cet affichage que l'ordonnancement est différent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cas 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulions montrer sur un problème avec plus de tâches que le choix du parcours pouvait être très impactant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sols = show_solution_tree(instance4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois de plus nous pouvons voir que le parcours en profondeur est plus efficace. Il ne traite que 63 contre 439 pour le parcours en profondeur et 425 pour le parcours en fonction des meilleures lower bound. Ces exemples montrent que le type de parcours est très important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Etude des temps de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons mis des captures dans cette partie car l'execution du code complet prend plusieurs heures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code en annexe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons cherché à derterminer quel parcours était le plus efficace. Cela dépend de notre heuristique pour faire le branchement. Nous avons fait une petite étude pour regarder la qualité de la règle de Schrage. Nous avons rélevé le nombre de problème résolu en 1 itération sur des problèmes de tailles variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\accuracy_shrag.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que Schrage permet de trouver dans la moitié des cas la solution en une itération."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons testé précédement sur beaucoup de problèmes que les Branch and Bound et MIP donnaient les mêmes solutions. Nous nous étions restreint sur la taille des problèmes car le MIP est peu performant pour les instances avec plus d'une dizaine de tâches. \n",
    "\n",
    "Nous avons refait une étude avec des plus gros problèmes comportants entre 10 et 30 tâches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\comp_bb_1.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\comp_bb_2.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\comp_bb_3.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir sur cette partie que nous avons des observations différentes de celles que nous avions avec des petites instances. En effet, précédemment nous avions vu que le parcours en profondeur était moins performant sur des petites instances. Maintenant, nous pouvons voir que le parcours en profondeur est plus performant en moyenne. De plus, les temps sont plus homogènes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour observer si le choix du parcours dépend de la taille des problèmes. Nous avons mené cette étude : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons récupéré le temps de calcul pour des tailles de problèmes allant de 3 à 29 tâches. Nous avons représenté le temps de calcul moyen. Nous avons pour cela réalisé 1000 problèmes pour tous les problèmes de taille allant de 3 à 29."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(path_image+\"\\\\comp_nbr_inst_croiss.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que le parcours en profondeur semble être le plus efficace en moyenne. Jusqu'à 15 tâches, nous pouvons voir que les temps de calcul sont similaires. Cependant, pour des problèmes allant de 15 à 30 tâches, le parcours en profondeur est systématiquement meilleur ou équivalent. Le parcours en profondeur et best lower bound se confondent sur ce graphique (c'est pour cela que la courbe rouge est caché sur plusieurs portions.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Travail effectué"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons mis en place des algorithmes de résolution du problème d'ordonnancement à une machine. Ces algorithmes ont été mis à jour par rapport à leur première version pour optimiser le temps de calcul. Dans le MIP, on a supprimé des contraintes redondantes. Dans le Branch and Bound, on ne traite que les noeuds qui possèdent potentiellement des solutions et nous avons modifié l'algorithme classique de Bellman.\n",
    "\n",
    "Ensuite, nous avons vérifié nos modèles sur des millions d'instances. La seconde partie de notre étude a consisté à comparer les deux approches : MIP et Branch-and-Bound. Puis nous avons comparé les différents parcours. Cela nous a permi de mettre en avant que le parcours en profondeur était la méthode la plus efficace en temps de calcul. Nous nous méfions avant de dire que le MIP est moins efficace car nous avons utilisé des solvers basiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons pu mettre en avant sur un point qui ne semblait pas évident au premier abord. En effet, il nous semblait que les solvers étaient très optimisés et donc bien plus performants que des methodes que l'on pouvait faire par nous même. Cela n'est donc pas le cas et cela même sur un problème relativement simple.\n",
    "\n",
    "Si nous avions disposé de plus de temps, nous aurions pu rendre une interface de visualisation. Nous avons quasiement fait tous les processus que l'on pourrait faire en entreprise. Mais comme l'application finale est destinée à des personnes ne sachant peut être pas utiliser Python, il peut être essentiel de faire une application **Dash** qui utilise le package **plotly** que nous avons utilisé.\n",
    "\n",
    "Enfin, une dernière perspective d'amélioration que nous pouvons imaginer est de faire de la programmation en parallèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Annexe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les codes prenant trop de temps ou les premières versions non optimisées de certains algorithmes. Cependant, nous n'avons pas fait figurer les codes dans le rapport car nous avons laissé que les versions les plus optimisées. Nous avons choisi de présenter en annexe les codes intermédiaires.\n",
    "\n",
    "\n",
    "**Remarque : les codes en Annexe peuvent prendre plusieurs heures pour s'executer. Si ils sont executés en simultané, ils peuvent faire planter l'ordinateur. Ainsi, nous vous conseillons de ne pas les executer.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(333)\n",
    "n_jobs = np.arange(4,11)\n",
    "temps_calcul = np.zeros((2,len(n_jobs))) \n",
    "\n",
    "for j in tqdm(n_jobs):\n",
    "    liste_1 = []\n",
    "    liste_2 = []\n",
    "    for i in range(20):\n",
    "        instance_test = gene_instance_test(j,30)\n",
    "        liste_1.append(solve_print_mip(instance_test,False)[\"duree\"])\n",
    "        liste_2.append(solve_print_mip_2(instance_test,False)[\"duree\"])\n",
    "    temps_calcul[0,j-4] = np.mean(np.array(liste_1))\n",
    "    temps_calcul[1,j-4] = np.mean(np.array(liste_2))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(n_jobs,temps_calcul[0,:],c ='rebeccapurple',label='Solveur MIP 1')\n",
    "plt.scatter(n_jobs,temps_calcul[1,:],c ='springgreen',label='Solveur MIP 2')\n",
    "plt.grid()\n",
    "plt.xlabel('Nombre de tâches')\n",
    "plt.ylabel('Temps de calcul')\n",
    "plt.title('Mise en avant temps de calcul')\n",
    "plt.legend(loc ='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_print_mip_2_GLPK_CMD(instance):\n",
    "    N = np.shape(instance['a'])[0]\n",
    "    \n",
    "    model = make_mip_2(instance)\n",
    "    \n",
    "    # Résoud avec le solveur voulu/disponible\n",
    "    starttime=time() # Obtenir le temps avant de lancer le solveur\n",
    "    # Résoud le MIP\n",
    "    model.solve(GLPK_CMD(msg=False))\n",
    "    \n",
    "    duree = time() - starttime\n",
    "\n",
    "    return duree  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_print_mip_2_CPLEX_PY(instance):\n",
    "    N = np.shape(instance['a'])[0]\n",
    "    \n",
    "    model = make_mip_2(instance)\n",
    "    \n",
    "    # Résoud avec le solveur voulu/disponible\n",
    "    starttime=time() # Obtenir le temps avant de lancer le solveur\n",
    "    # Résoud le MIP\n",
    "    model.solve(CPLEX_PY(msg=False))\n",
    "    \n",
    "    duree = time() - starttime\n",
    "\n",
    "    return duree  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_print_mip_2_GUROBI(instance):\n",
    "    N = np.shape(instance['a'])[0]\n",
    "    \n",
    "    model = make_mip_2(instance)\n",
    "    \n",
    "    # Résoud avec le solveur voulu/disponible\n",
    "    starttime=time() # Obtenir le temps avant de lancer le solveur\n",
    "    # Résoud le MIP\n",
    "    model.solve(GUROBI(msg=False))\n",
    "    \n",
    "    duree = time() - starttime\n",
    "\n",
    "    return duree  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_print_mip_2_COIN_CMD(instance):\n",
    "    N = np.shape(instance['a'])[0]\n",
    "    \n",
    "    model = make_mip_2(instance)\n",
    "    \n",
    "    # Résoud avec le solveur voulu/disponible\n",
    "    starttime=time() # Obtenir le temps avant de lancer le solveur\n",
    "    # Résoud le MIP\n",
    "    model.solve(COIN_CMD(msg=False))\n",
    "    \n",
    "    duree = time() - starttime\n",
    "\n",
    "    return duree  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = np.arange(4,10)\n",
    "temps_calcul = np.zeros( ((len(liste_solveurs)-1),len(n_jobs)) )\n",
    "for j in n_jobs:\n",
    "    liste_1 = []\n",
    "    liste_2 = []\n",
    "    liste_3 = []\n",
    "    liste_4 = []\n",
    "    # on moyenne sur 20 instances\n",
    "    for k in range(20):\n",
    "        instance_test = gene_instance_test(j,30)\n",
    "        liste_1.append(solve_print_mip_2_COIN_CMD(instance_test))\n",
    "        liste_2.append(solve_print_mip_2_CPLEX_PY(instance_test))\n",
    "        liste_3.append(solve_print_mip_2_GLPK_CMD(instance_test))\n",
    "        liste_4.append(solve_print_mip_2_GUROBI(instance_test))\n",
    "    temps_calcul[0,j-4] = np.mean(np.array(liste_1))\n",
    "    temps_calcul[1,j-4] = np.mean(np.array(liste_2))\n",
    "    temps_calcul[2,j-4] = np.mean(np.array(liste_3))\n",
    "    temps_calcul[3,j-4] = np.mean(np.array(liste_4)) \n",
    "    \n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.scatter(n_jobs,temps_calcul[0,:],c ='rebeccapurple',label='Solveur COIND_CMD')\n",
    "plt.scatter(n_jobs,temps_calcul[1,:],c ='springgreen',label='Solveur CPLEX_PY')\n",
    "plt.scatter(n_jobs,temps_calcul[2,:],c ='darkslategrey',label='Solveur GLPK_CMD')\n",
    "plt.scatter(n_jobs,temps_calcul[3,:],c ='sienna',label='Solveur GUROBI')\n",
    "plt.grid()\n",
    "plt.xlabel('Nombre de tâches')\n",
    "plt.ylabel('Temps de calcul')\n",
    "plt.title('Mise en avant temps de calcul par solveur')\n",
    "plt.legend(loc ='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bellman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons tester la première version avec ce Bellman et nous optenions toujours les mêmes résultats qu'avec le nouveau plus long chemin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makespan(G):\n",
    "        \n",
    "        # chemin\n",
    "        path = []\n",
    "        \n",
    "   \n",
    "        #Résolution    \n",
    "        distances = {}\n",
    "        predecesseurs = {}\n",
    "        for sommet in list(G.nodes):\n",
    "            distances[sommet] = -math.inf\n",
    "            predecesseurs[sommet] = None\n",
    "        distances['s'] = 0\n",
    "\n",
    "\n",
    "        for i in range(len(list(G.nodes))):\n",
    "            for s in list(G.nodes):\n",
    "                for pred in list(G.predecessors(s)):\n",
    "                    if(distances[pred] + G[pred][s]['weight'] >= distances[s]):\n",
    "                        distances[s] = distances[pred] + G[pred][s]['weight']\n",
    "                        predecesseurs[s] = pred\n",
    "        \n",
    "        # on récupère le chemin\n",
    "        i = \"t\"\n",
    "        while(predecesseurs[i] !=\"s\"):\n",
    "            i = predecesseurs[i]\n",
    "            path.insert(0,i)\n",
    "            \n",
    "        return{\"makespan\":distances['t'],\"path\":np.array(path)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des plus long chemin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps1 = {}\n",
    "tps2 = {}\n",
    "for i in tqdm(range(20000)):\n",
    "    tps1[i]=[]\n",
    "    tps2[i]=[]\n",
    "    r = 15\n",
    "    w = random.randint(30,300)\n",
    "    instance = gene_instance_test(r,w)\n",
    "        \n",
    "    for type_p in [\"profondeur\",\"largeur\",\"best_lower\"]:\n",
    "        start = time()\n",
    "        # version 1\n",
    "        E = EnumerationTree(instance)\n",
    "        while len(E.proceed_node)!=0:\n",
    "            E.creating_branching(type_p,1)\n",
    "        sol = find_solution(E)[0]\n",
    "        tps1[i].append(time()-start)\n",
    "        start = time()\n",
    "        # version 2\n",
    "        E = EnumerationTree(instance)\n",
    "        while len(E.proceed_node)!=0:\n",
    "            E.creating_branching(type_p,0)\n",
    "        sol = find_solution(E)[0]\n",
    "        tps2[i].append(time()-start)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des résultats des modèles sur des millions de problèmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaison MIP et B&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = []\n",
    "tps = {}\n",
    "for i in tqdm(range(100000)):\n",
    "    tps[i]=[]\n",
    "    r = random.choices(np.array([i for i in range(2,8)]), weights=list(np.arange(7,1,-1)))[0]\n",
    "    w = random.randint(30,300)\n",
    "    instance = gene_instance_test(r,w)\n",
    "    compute_solve_print_mip = solve_print_mip_2(instance,False)\n",
    "    best_list = compute_solve_print_mip[\"makespan\"]\n",
    "    tps[i].append(compute_solve_print_mip[\"duree\"])\n",
    "    \n",
    "    for type_p in [\"profondeur\",\"largeur\",\"best_lower\"]:\n",
    "        start = time()\n",
    "        E = EnumerationTree(instance)\n",
    "        while len(E.proceed_node)!=0:\n",
    "            E.creating_branching(type_p)\n",
    "        sol = find_solution(E)[0]\n",
    "        tps[i].append(time()-start)\n",
    "        H = conjunctive_graph(instance,E.dict_node[sol].S)\n",
    "        if best_list == makespan_2(H)[\"makespan\"]:\n",
    "            pass\n",
    "        else : \n",
    "            print(\"error\")\n",
    "            error.append(instance.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des temps de calcul moyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les B&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps = {}\n",
    "for i in tqdm(range(1000)):\n",
    "    tps[i]=[]\n",
    "    r = random.choices(np.array([i for i in range(10,30)]), weights=list(np.arange(29,9,-1)))[0]\n",
    "    w = random.randint(30,300)\n",
    "    instance = gene_instance_test(r,w)\n",
    "        \n",
    "    for type_p in [\"profondeur\",\"largeur\",\"best_lower\"]:\n",
    "        start = time()\n",
    "        E = EnumerationTree(instance)\n",
    "        while len(E.proceed_node)!=0:\n",
    "            E.creating_branching(type_p)\n",
    "        sol = find_solution(E)[0]\n",
    "        tps[i].append(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison avec des tailles de problèmes croissants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tps1 = {}\n",
    "tps2 = {}\n",
    "tps3 = {}\n",
    "for i in tqdm(range(3,30,2)):\n",
    "    tps1[i]=[]\n",
    "    tps2[i]=[]\n",
    "    tps3[i]=[]\n",
    "    \n",
    "    r = i\n",
    "    w = random.randint(30,300)\n",
    "    instance = gene_instance_test(r,w)\n",
    "    for j in range(1000):\n",
    "                \n",
    "        # profondeur\n",
    "        \n",
    "        start = time()\n",
    "        E = EnumerationTree(instance)\n",
    "        while len(E.proceed_node)!=0:\n",
    "            E.creating_branching(\"profondeur\")\n",
    "        sol = find_solution(E)[0]\n",
    "        tps1[i].append(time()-start)\n",
    "        \n",
    "        \n",
    "        # largeur\n",
    "        \n",
    "        start = time()\n",
    "        E = EnumerationTree(instance)\n",
    "        while len(E.proceed_node)!=0:\n",
    "            E.creating_branching(\"largeur\")\n",
    "        sol = find_solution(E)[0]\n",
    "        tps2[i].append(time()-start)\n",
    "        \n",
    "        # best_lower\n",
    "        \n",
    "        start = time()\n",
    "        E = EnumerationTree(instance)\n",
    "        while len(E.proceed_node)!=0:\n",
    "            E.creating_branching(\"best_lower\")\n",
    "        sol = find_solution(E)[0]\n",
    "        tps3[i].append(time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nombre de problème résolu avec shrag en 1 itération"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt = 0\n",
    "cpt1 = 0\n",
    "for i in tqdm(range(3,20,2)):\n",
    "    \n",
    "    for j in range(1000):\n",
    "        r = i\n",
    "        w = random.randint(30,300)\n",
    "        instance = gene_instance_test(r,w)\n",
    "        cpt1+=1      \n",
    "       \n",
    "        E = EnumerationTree(instance)\n",
    "        while len(E.proceed_node)!=0:\n",
    "            E.creating_branching(\"profondeur\")\n",
    "        if len(E.dict_node)==1:\n",
    "            cpt+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Nombre d'instance total\":[cpt1],\"Nombre d'instance résolu en 1 itération\":[cpt]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version des packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- alabaster                          0.7.12\n",
    "- amply                              0.1.4\n",
    "- anaconda-client                    1.7.2\n",
    "- anaconda-navigator                 1.10.0\n",
    "- anaconda-project                   0.8.3\n",
    "- argh                               0.26.2\n",
    "- argon2-cffi                        20.1.0\n",
    "- asn1crypto                         1.4.0\n",
    "- astroid                            2.4.2\n",
    "- astropy                            4.0.2\n",
    "- async-generator                    1.10\n",
    "- atomicwrites                       1.4.0\n",
    "- attrs                              20.3.0\n",
    "- autopep8                           1.5.4\n",
    "- Babel                              2.8.1\n",
    "- backcall                           0.2.0\n",
    "- backports.functools-lru-cache      1.6.1\n",
    "- backports.shutil-get-terminal-size 1.0.0\n",
    "- backports.tempfile                 1.0\n",
    "- backports.weakref                  1.0.post1\n",
    "- bcrypt                             3.2.0\n",
    "- beautifulsoup4                     4.9.3\n",
    "- bitarray                           1.6.1\n",
    "- bkcharts                           0.2\n",
    "- bleach                             3.2.1\n",
    "- bokeh                              2.2.3\n",
    "- boto                               2.49.0\n",
    "- Bottleneck                         1.3.2\n",
    "- branca                             0.4.2\n",
    "- Brotli                             1.0.9\n",
    "- brotlipy                           0.7.0\n",
    "- certifi                            2020.6.20\n",
    "- cffi                               1.14.3\n",
    "- chardet                            3.0.4\n",
    "- click                              7.1.2\n",
    "- cloudpickle                        1.6.0\n",
    "- clyent                             1.2.2\n",
    "- colorama                           0.4.4\n",
    "- comtypes                           1.1.7\n",
    "- conda                              4.11.0\n",
    "- conda-build                        3.20.5\n",
    "- conda-package-handling             1.7.2\n",
    "- conda-verify                       3.4.2\n",
    "- contextlib2                        0.6.0.post1\n",
    "- cryptography                       3.1.1\n",
    "- cycler                             0.10.0\n",
    "- Cython                             0.29.21\n",
    "- cytoolz                            0.11.0\n",
    "- dash                               2.0.0\n",
    "- dash-core-components               2.0.0\n",
    "- dash-html-components               2.0.0\n",
    "- dash-table                         5.0.0\n",
    "- dask                               2.30.0\n",
    "- decorator                          4.4.2\n",
    "- defusedxml                         0.6.0\n",
    "- diff-match-patch                   20200713\n",
    "- distributed                        2.30.1\n",
    "- docutils                           0.16\n",
    "- entrypoints                        0.3\n",
    "- et-xmlfile                         1.0.1\n",
    "- fastcache                          1.1.0\n",
    "- ffmpeg                             1.4\n",
    "- filelock                           3.0.12\n",
    "- flake8                             3.8.4\n",
    "- Flask                              1.1.2\n",
    "- Flask-Compress                     1.10.1\n",
    "- folium                             0.12.1\n",
    "- fsspec                             0.8.3\n",
    "- future                             0.18.2\n",
    "- gevent                             20.9.0\n",
    "- glob2                              0.7\n",
    "- graphviz                           0.13\n",
    "- greenlet                           0.4.17\n",
    "- gurobipy                           9.1.2\n",
    "- h5py                               2.10.0\n",
    "- HeapDict                           1.0.1\n",
    "- html5lib                           1.1\n",
    "- huepy                              1.2.1\n",
    "- idna                               2.10\n",
    "- imageio                            2.9.0\n",
    "- imageio-ffmpeg                     0.4.3\n",
    "- imagesize                          1.2.0\n",
    "- importlib-metadata                 2.0.0\n",
    "- iniconfig                          1.1.1\n",
    "- instabot                           0.117.0\n",
    "- intervaltree                       3.1.0\n",
    "- ipykernel                          5.3.4\n",
    "- ipython                            7.19.0\n",
    "- ipython-genutils                   0.2.0\n",
    "- ipywidgets                         7.5.1\n",
    "- iso8601                            0.1.14\n",
    "- isort                              5.6.4\n",
    "- itsdangerous                       1.1.0\n",
    "- jdcal                              1.4.1\n",
    "- jedi                               0.17.1\n",
    "- Jinja2                             2.11.2\n",
    "- joblib                             0.17.0\n",
    "- json5                              0.9.5\n",
    "- jsonschema                         3.2.0\n",
    "- jupyter                            1.0.0\n",
    "- jupyter-client                     6.1.7\n",
    "- jupyter-console                    6.2.0\n",
    "- jupyter-core                       4.6.3\n",
    "- jupyterlab                         2.2.6\n",
    "- jupyterlab-pygments                0.1.2\n",
    "- jupyterlab-server                  1.2.0\n",
    "- keyring                            21.4.0\n",
    "- kiwisolver                         1.3.0\n",
    "- lazy-object-proxy                  1.4.3\n",
    "- libarchive-c                       2.9\n",
    "- llvmlite                           0.34.0\n",
    "- locket                             0.2.0\n",
    "- lxml                               4.6.1\n",
    "- MarkupSafe                         1.1.1\n",
    "- matplotlib                         3.3.2\n",
    "- mccabe                             0.6.1\n",
    "- menuinst                           1.4.16\n",
    "- mistune                            0.8.4\n",
    "- mkl-fft                            1.2.0\n",
    "- mkl-random                         1.1.1\n",
    "- mkl-service                        2.3.0\n",
    "- mock                               4.0.2\n",
    "- more-itertools                     8.6.0\n",
    "- moviepy                            1.0.3\n",
    "- mpmath                             1.1.0\n",
    "- msgpack                            1.0.0\n",
    "- multipledispatch                   0.6.0\n",
    "- navigator-updater                  0.2.1\n",
    "- nbclient                           0.5.1\n",
    "- nbconvert                          6.0.7\n",
    "- nbformat                           5.0.8\n",
    "- nest-asyncio                       1.4.2\n",
    "- networkx                           2.5\n",
    "- nltk                               3.5\n",
    "- nose                               1.3.7\n",
    "- notebook                           6.1.4\n",
    "- numba                              0.51.2\n",
    "- numexpr                            2.7.1\n",
    "- numpy                              1.19.2\n",
    "- numpydoc                           1.1.0\n",
    "- olefile                            0.46\n",
    "- openpyxl                           3.0.5\n",
    "- osmiter                            1.1.1\n",
    "- packaging                          20.4\n",
    "- pandas                             1.1.3\n",
    "- pandocfilters                      1.4.3\n",
    "- paramiko                           2.7.2\n",
    "- parso                              0.7.0\n",
    "- partd                              1.1.0\n",
    "- path                               15.0.0\n",
    "- pathlib2                           2.3.5\n",
    "- pathtools                          0.1.2\n",
    "- patsy                              0.5.1\n",
    "- pep8                               1.7.1\n",
    "- pexpect                            4.8.0\n",
    "- phantomjs                          1.4.1\n",
    "- pickleshare                        0.7.5\n",
    "- Pillow                             8.0.1\n",
    "- pip                                20.2.4\n",
    "- pkginfo                            1.6.1\n",
    "- plotly                             5.3.1\n",
    "- pluggy                             0.13.1\n",
    "- ply                                3.11\n",
    "- proglog                            0.1.9\n",
    "- prometheus-client                  0.8.0\n",
    "- prompt-toolkit                     3.0.8\n",
    "- protobuf                           3.17.0\n",
    "- psutil                             5.7.2\n",
    "- PuLP                               2.4\n",
    "- py                                 1.9.0\n",
    "- pycodestyle                        2.6.0\n",
    "- pycosat                            0.6.3\n",
    "- pycparser                          2.20\n",
    "- pycurl                             7.43.0.6\n",
    "- pydocstyle                         5.1.1\n",
    "- pydot                              1.4.2\n",
    "- pyflakes                           2.2.0\n",
    "- Pygments                           2.7.2\n",
    "- pylint                             2.6.0\n",
    "- pymongo                            3.12.0\n",
    "- PyNaCl                             1.4.0\n",
    "- pyodbc                             4.0.0-unsupported\n",
    "- pyOpenSSL                          19.1.0\n",
    "- pyparsing                          2.4.7\n",
    "- pyreadline                         2.1\n",
    "- pyroutelib3                        1.7.1\n",
    "- pyrsistent                         0.17.3\n",
    "- PySocks                            1.7.1\n",
    "- pytest                             6.2.3\n",
    "- python-dateutil                    2.8.1\n",
    "- python-jsonrpc-server              0.4.0\n",
    "- python-language-server             0.35.1\n",
    "- pytz                               2020.1\n",
    "- PyWavelets                         1.1.1\n",
    "- pywin32                            227\n",
    "- pywin32-ctypes                     0.2.0\n",
    "- pywinpty                           0.5.7\n",
    "- PyYAML                             5.3.1\n",
    "- pyzmq                              19.0.2\n",
    "- QDarkStyle                         2.8.1\n",
    "- QtAwesome                          1.0.1\n",
    "- qtconsole                          4.7.7\n",
    "- QtPy                               1.9.0\n",
    "- regex                              2020.10.15\n",
    "- requests                           2.24.0\n",
    "- requests-toolbelt                  0.9.1\n",
    "- responses                          0.13.2\n",
    "- rope                               0.18.0\n",
    "- Rtree                              0.9.4\n",
    "- ruamel-yaml                        0.15.87\n",
    "- schedule                           1.1.0\n",
    "- scikit-image                       0.17.2\n",
    "- scikit-learn                       0.23.2\n",
    "- scipy                              1.5.2\n",
    "- seaborn                            0.11.0\n",
    "- selenium                           3.141.0\n",
    "- Send2Trash                         1.5.0\n",
    "- setuptools                         50.3.1.post20201107\n",
    "- simplegeneric                      0.8.1\n",
    "- singledispatch                     3.4.0.3\n",
    "- sip                                4.19.13\n",
    "- six                                1.15.0\n",
    "- snowballstemmer                    2.0.0\n",
    "- sortedcollections                  1.2.1\n",
    "- sortedcontainers                   2.2.2\n",
    "- soupsieve                          2.0.1\n",
    "- Sphinx                             3.2.1\n",
    "- sphinxcontrib-applehelp            1.0.2\n",
    "- sphinxcontrib-devhelp              1.0.2\n",
    "- sphinxcontrib-htmlhelp             1.0.3\n",
    "- sphinxcontrib-jsmath               1.0.1\n",
    "- sphinxcontrib-qthelp               1.0.3\n",
    "- sphinxcontrib-serializinghtml      1.1.4\n",
    "- sphinxcontrib-websupport           1.2.4\n",
    "- spyder                             4.1.5\n",
    "- spyder-kernels                     1.9.4\n",
    "- SQLAlchemy                         1.3.20\n",
    "- statsmodels                        0.12.0\n",
    "- sympy                              1.6.2\n",
    "- tables                             3.6.1\n",
    "- tblib                              1.7.0\n",
    "- tenacity                           8.0.1\n",
    "- terminado                          0.9.1\n",
    "- testpath                           0.4.4\n",
    "- threadpoolctl                      2.1.0\n",
    "- tifffile                           2020.10.1\n",
    "- toml                               0.10.1\n",
    "- toolz                              0.11.1\n",
    "- tornado                            6.0.4\n",
    "- tqdm                               4.50.2\n",
    "- traitlets                          5.0.5\n",
    "- typing-extensions                  3.7.4.3\n",
    "- ujson                              4.0.1\n",
    "- unicodecsv                         0.14.1\n",
    "- urllib3                            1.25.11\n",
    "- watchdog                           0.10.3\n",
    "- wcwidth                            0.2.5\n",
    "- webencodings                       0.5.1\n",
    "- Werkzeug                           1.0.1\n",
    "- wheel                              0.35.1\n",
    "- widgetsnbextension                 3.5.1\n",
    "- win-inet-pton                      1.1.0\n",
    "- win-unicode-console                0.5\n",
    "- wincertstore                       0.2\n",
    "- wrapt                              1.11.2\n",
    "- xlrd                               1.2.0\n",
    "- XlsxWriter                         1.3.7\n",
    "- xlwings                            0.20.8\n",
    "- xlwt                               1.3.0\n",
    "- xmltodict                          0.12.0\n",
    "- yapf                               0.30.0\n",
    "- zict                               2.0.0\n",
    "- zipp                               3.4.0\n",
    "- zope.event                         4.5.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
